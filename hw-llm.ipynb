{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Large Language Models\n",
    "\n",
    "An PDF overview of the homework is [here](https://www.cs.jhu.edu/~jason/465/hw-llm/).\n",
    "\n",
    "It mentions: \"We'll send hand-in instructions soon.  Probably we will ask you to submit a version\n",
    "of the main notebook, with your answers added and extraneous materials deleted. We may also\n",
    "ask for a summary.\"\n",
    "\n",
    "![image](handin.png)\n",
    "This symbol marks a question or exercise that you will be expected to hand in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Getting started\n",
    "\n",
    "## Update `conda` environment\n",
    "\n",
    "Download the updated [nlp-class.yml](http://cs.jhu.edu/~jason/465/hw-llm/nlp-class.yml) file, and execute\n",
    "```\n",
    "conda env update --file nlp-class.yml --prune\n",
    "```\n",
    "to make sure that all the packages you need are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch code and data files for this homework\n",
    "\n",
    "These files may get improved after the homework is released, so you should probably re-download them periodically.\n",
    "\n",
    "Here is a command you can type.  We won't put it in a code cell, because we don't want you to execute it accidentally in the current directory and overwrite your own changes.  (Actually, it will not overwrite your versions of the files — they will be renamed with names like `argubots.py.1`.)\n",
    "\n",
    "```\n",
    "!wget --quiet -r -np -nH --cut-dirs=3 -A '*.txt' -A '*.py' -A 'demo.ipynb' -A '*.png' https://www.cs.jhu.edu/~jason/465/hw-llm/\n",
    "!rm -f data/*.1 *.png.1 robots.txt   # remove any backup versions of the static files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r--@ 1 benjamin  staff  13848 Dec  4 03:18 agents.py\n",
      "-rw-rw-r--@ 1 benjamin  staff  24584 Dec 10 03:11 argubots.py\n",
      "-rw-rw-r--@ 1 benjamin  staff   2827 Dec  4 13:17 characters.py\n",
      "-rw-rw-r--@ 1 benjamin  staff   6685 Dec  4 00:28 dialogue.py\n",
      "-rw-rw-r--@ 1 benjamin  staff  10463 Dec  4 19:13 eval.py\n",
      "-rw-rw-r--@ 1 benjamin  staff  10408 Dec  4 04:11 kialo.py\n",
      "-rw-rw-r--@ 1 benjamin  staff   1347 Dec  3 18:44 logging_cm.py\n",
      "-rw-rw-r--@ 1 benjamin  staff   1106 Dec  3 18:53 simulate.py\n",
      "-rw-rw-r--@ 1 benjamin  staff   3780 Dec 10 01:20 tracking.py\n",
      "\n",
      "data:\n",
      "total 4512\n",
      "-rw-rw-r--@ 1 benjamin  staff     407 Nov 29 03:00 LICENSE\n",
      "-rw-rw-r--@ 1 benjamin  staff  613106 Nov 25 17:04 all-humans-should-be-vegan-2762.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff   81917 Nov 29 21:56 have-authoritarian-governments-handled-covid-19-better-than-others-54145.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff   52771 Dec  4 04:40 is-biden-an-incompetent-president-44217.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff  153551 Dec  4 04:39 is-joe-biden-a-good-president-53071.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff   60556 Dec  4 04:39 is-joe-biden-better-than-donald-trump-39949.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff  113781 Nov 29 21:52 should-covid-19-vaccines-be-mandatory-39517.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff   19702 Nov 25 17:04 should-enforcing-a-vegan-diet-on-children-be-condemned-as-child-abuse-33850.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff    6615 Nov 25 17:04 should-people-go-vegan-if-they-can-31640.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff   18637 Nov 29 21:55 should-schools-close-during-the-covid-19-pandemic-44845.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff  704648 Nov 25 17:04 the-ethics-of-eating-animals-is-eating-meat-wrong-1229.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff  376707 Dec  4 04:37 was-donald-trump-a-good-president-6079.txt\n",
      "-rw-rw-r--@ 1 benjamin  staff   87301 Dec  4 04:36 was-trump-a-good-president-3295.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lR *.py data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install faiss-cpu\n",
    "!pip3 install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `autoimport` feature of Jupyter ensures that if an imported module (.py file) changes, the notebook will automatically import the new version.  \n",
    "(However, objects that were defined with the old version of the class won't change.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell does some magic that makes \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an OpenAI client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An OpenAI API key will be sent to you.\n",
    "Make an `.env` file in the same directory as this notebook, containing the following:\n",
    "```\n",
    "export OPENAI_API_KEY=[your API key]    # do not include the brackets here\n",
    "```\n",
    "Make sure others can't read this file:\n",
    "```\n",
    "chmod 600 .env\n",
    "```\n",
    "\n",
    "**Be sure to keep the key secret.  It gives access to a billable account.** If OpenAI finds it on the public web, they will invalidate it, and then no one (including you) can use this key to make requests anymore.\n",
    "\n",
    "Now you can execute the following to get an OpenAI client object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import openai\n",
    "from tracking import track_usage, read_usage\n",
    "\n",
    "dotenv.load_dotenv(override=True)      # define environment variables from .env\n",
    "client = track_usage(openai.OpenAI())  # create a client, modified to record its usage to a local file \n",
    "\n",
    "# Or use our tracking module to do the above for you, like this:\n",
    "\n",
    "# from tracking import default_client\n",
    "# client = default_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job of the client is to talk to the OpenAI server over HTTP.\n",
    "The `OpenAI` constructor has some optional arguments that configure these HTTP messages.\n",
    "However, the defaults should work fine for you.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the model!\n",
    "\n",
    "You can now get answers from OpenAI models by calling methods of the `client` instance.  \n",
    "You will have to specify which OpenAI model to use.\n",
    "Documentation of the methods is [here](https://pypi.org/project/openai/) if you are curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue a textual prompt\n",
    "\n",
    "This is what language models excel at.  In principle you should do it by calling [`client.completions.create`](https://platform.openai.com/docs/api-reference/completions/create?lang=python).  But OpenAI's newer models don't support that legacy API, and the older ones are being [retired in January 2024](https://openai.com/blog/gpt-4-api-general-availability).  So we'll use the more modern API, [`client.chat.completions.create`](https://platform.openai.com/docs/api-reference/chat/create?lang=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-8UMwk6UJ6rsLeQL14BEquvQ0NA0bK'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1. Mercury'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1702248738</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-1106'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_eeff13170a'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-8UMwk6UJ6rsLeQL14BEquvQ0NA0bK'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'1. Mercury'\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1702248738\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-1106'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_eeff13170a'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m20\u001b[0m, \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1. Mercury'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "        \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcontent\u001b[0m=\u001b[32m'1. Mercury'\u001b[0m,\n",
       "            \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Mercury\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m. Mercury\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rich   # prettyprinting\n",
    "\n",
    "response = client.chat.completions.create(messages=[{\"role\": \"user\", \n",
    "                                                     \"content\": \"Q: Name the planets in the solar system?\\nA: \"}], \n",
    "                                          model=\"gpt-3.5-turbo-1106\",  # which model to use\n",
    "                                          temperature=1,               # get a little variety\n",
    "                                          max_tokens=64,               # limit on length of result\n",
    "                                          stop=[\"Q:\", \"\\n\"])           # treat these as EOS symbols\n",
    "rich.print(response)                              # the full object that was sent back from the server\n",
    "rich.print(response.choices)                      # just the list of 1 answer (the default, but calling with n=5 would give 5 answers) \n",
    "rich.print(response.choices[0].message.content)   # extract the good stuff from that 1 answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](handin.png)\n",
    "Try running the cell above a few times. You may get different random answers — especially because the call specifies temperature 1.  (The default temperature is rumored to be 0.8.) Are the answers all equally good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It might be handy to package up what we just did.<br>\n",
    "The `complete` function below is a convenient way of experimenting with completing text.\n",
    "It is illustrated with a grocery example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', and flour. I also picked up some grapes, honey, ice cream, and juice. Lastly, I grabbed some kiwi, lemons, milk, and nuts. My shopping list was quite diverse!',\n",
       " ', and flour. I also picked up some grapes, honey, ice cream, and juice. Additionally, I grabbed some kale, lemons, milk, nuts, and oatmeal. Finally, I got some pears, quinoa, rice, spinach, and tomatoes. My shopping trip was quite successful!',\n",
       " \", and flour. I also picked up some grapes, honey, ice cream, juice, and kiwi. Lastly, I grabbed some lemons, milk, nuts, oranges, and pasta. My shopping trip was a success and I can't wait to enjoy all the delicious items I bought.\",\n",
       " ', and flour. I also picked up some grapes, honey, ice cream, and jam. Additionally, I grabbed some kiwi, lemons, milk, and nuts. Finally, I got some oranges, peanut butter, quinoa, rice, and spinach.',\n",
       " ', and fish.',\n",
       " ', and flour. I also picked up some groceries like milk, bread, and cheese. After that, I decided to treat myself to some ice cream and chocolate. Finally, I grabbed some fresh vegetables like lettuce, tomatoes, and cucumbers. Overall, it was a successful shopping trip!',\n",
       " ', and flour.',\n",
       " ', and flour. I also picked up some groceries like milk, bread, and cheese. After that, I grabbed some snacks like chips and cookies. Finally, I got some household items like toilet paper and laundry detergent. It was a successful shopping trip!',\n",
       " ', and flour.',\n",
       " ', and flour. I also picked up some groceries like milk, bread, and cheese. Finally, I grabbed some toiletries like shampoo, toothpaste, and soap. It was a successful shopping trip!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete(client, s: str, model=\"gpt-3.5-turbo-1106\", *args, **kwargs):\n",
    "    response = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": s}],\n",
    "                                              model=model,\n",
    "                                              *args, **kwargs)\n",
    "    return [choice.message.content for choice in response.choices]\n",
    "\n",
    "complete(client, \"I went to the store and I bought apples, bananas, cherries, donuts, eggs\", \n",
    "         n=10, temperature=0.5, max_tokens=96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](handin.png)\n",
    "Anything could be on a grocery list, so why are the 10 different completions above so similar?<br>\n",
    "Hint: The answer isn't just the temperature of 0.5.  Look especially at the long completions; run the cell again if you didn't get multiple long completions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![image](handin.png)\n",
    "What happens at different temperatures?  How about temperatures > 1?  (Note: Higher temperatures tend to produce longer responses, so it's wise to use `max_tokens`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Remarks:* [In the future](https://community.openai.com/t/logprobs-are-missing-from-the-chat-endpoints/289514), you will be able to specify an argument `logprobs=5` to also get the log-probabilities of all generated tokens and of the top-5 tokens at each step.  That will produce much more output.  (This argument has always been available for the legacy API, and is available in the [Python bindings for open-source models such as Llama](https://pypi.org/project/llama-cpp-python/).  The Llama bindings also allow you to [constrain the output by an arbitrary CFG](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md), using `grammar=...`.  This is useful if you're generating code or data that must be syntactically valid to be useful to you.  However, the OpenAI API only allows you to [constrain the output to be valid JSON](https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a function using instructions and few-shot prompting\n",
    "\n",
    "Now let's try passing a sequence of multiple messages into the chat completions API.  In this case, we provide some instructions and one-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-8U9bWjx9XqPneBSVzH1zofA0F0Vkn'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'furiously sleep ideas green colorless'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1702197450</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-1106'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_eeff13170a'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-8U9bWjx9XqPneBSVzH1zofA0F0Vkn'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'furiously sleep ideas green colorless'\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1702197450\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-1106'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_eeff13170a'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m7\u001b[0m, \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m50\u001b[0m, \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m57\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'furiously sleep ideas green colorless'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(messages=[{ \"role\": \"system\",      # instructions\n",
    "                                                      \"content\": \"Reverse the order of the words.\" },\n",
    "                                                    { \"role\": \"user\",        # input\n",
    "                                                      \"content\": \"Good things come to those who wait.\" },\n",
    "                                                    { \"role\": \"assistant\",   # output\n",
    "                                                      \"content\": \"Wait who those to come things good.\" },\n",
    "                                                    { \"role\": \"user\",        # input\n",
    "                                                      \"content\": \"Colorless green ideas sleep furiously.\" }],\n",
    "                                          model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "rich.print(response)\n",
    "response.choices[0].message.content                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](handin.png)\n",
    "By modifying this call, can you get it to produce different versions of the output?\n",
    "Some possible behaviors you could try to arrange:\n",
    "* specific other way of formatting the output, e.g., `wait, who, those, to, come, things, good`\n",
    "* match the input's way of formatting the output (same use of capitalization, puncutation, commas)\n",
    "* reverse the phrases rather than reversing the words, e.g., `To those who wait come good things.` \n",
    "\n",
    "You can try playing with the number, the content, and the order of few-shot examples, and changing or removing the instructions.\n",
    "\n",
    "![image](handin.png)\n",
    "What happens if the examples don't match the instructions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's see how the above client has been tokenizing its input and output text.  For that we can use a tokenizer that runs locally, not in the cloud, and is guaranteed to get the same outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellooo, world!\n",
      "9906 \t Hello\n",
      "2689 \t oo\n",
      "11 \t ,\n",
      "1917 \t  world\n",
      "0 \t !\n",
      "Vocab size = 100277\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo-1106\")  # how this model will tokenize\n",
    "toks = tokenizer.encode(\"Hellooo, world!\") # list of integerized tokens, starting with BOS\n",
    "\n",
    "print(tokenizer.decode(toks))                             # convert list back to string\n",
    "for tok in toks: print(tok,\"\\t\",tokenizer.decode([tok]))  # convert one at a time\n",
    "print(\"Vocab size =\", tokenizer.n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try embedding some text\n",
    "\n",
    "Also just for fun, let's try the embedder, which converts a string to an fixed-length vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536-dimensional embedding starting with [0.021248681470751762, -0.014377851039171219, 0.010210818611085415, -0.02133774757385254, -0.00979093462228775]\n",
      "Squared length of embedding vector:  1.0000000629476622\n"
     ]
    }
   ],
   "source": [
    "emb_response = client.embeddings.create( input= [  # note: adjacent literal strings in Python are concatenated\n",
    "        \"When in the Course of human events it becomes necessary for one \"\n",
    "        \"people to dissolve the political bands which have connected them \"\n",
    "        \"with another, and to assume among the Powers of the earth, the \"\n",
    "        \"separate and equal station to which the Laws of Nature and of \"\n",
    "        \"Nature's God entitle them, a decent respect to the opinions of \"\n",
    "        \"mankind requires that they should declare the causes which impel \"\n",
    "        \"them to the separation.\" ], \n",
    "        model=\"text-embedding-ada-002\")   # the only OpenAI model that currently offers the embeddings API\n",
    "# don't print the whole response because it's very long\n",
    "e = emb_response.data[0].embedding\n",
    "print(f\"{len(e)}-dimensional embedding starting with {e[:5]}\")\n",
    "print(\"Squared length of embedding vector: \", sum(x**2 for x in e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your usage so far\n",
    "\n",
    "Please be careful not to write loops that use lots and lots of tokens.  That will cost us money, and could hit the per-day usage limit that is shared by the whole class.\n",
    "\n",
    "Execute one of these cells whenever you want to see your cost so far.  Or, just keep `usage_openai.json` open as a tab in your IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 59220,\n",
       " 'prompt_tokens': 735243,\n",
       " 'total_tokens': 794463,\n",
       " 'cost': 0.8524328999999977}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_usage()      # reads from the file usage_openai.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"completion_tokens\": 17394,\n",
      "    \"prompt_tokens\": 114143,\n",
      "    \"total_tokens\": 131537,\n",
      "    \"cost\": 0.14801840000000013\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat usage_openai.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogues and dialogue agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to create a good \"argubot\" that will talk to people about controversial topics and broaden their minds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first argubot (Airhead)\n",
    "\n",
    "You can have a conversation right now with a _really bad_ argubot named Airhead.  Try asking it about climate change!  When you're done, reply with an empty string.\n",
    "\n",
    "(The `converse()` method calls Python's `input()` function, which will prompt you for input at the command-line or by popping up a box in your IDE.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Airhead) I know right???\n",
      "(angad) Hi\n",
      "(Airhead) I know right???\n"
     ]
    }
   ],
   "source": [
    "import argubots\n",
    "d = argubots.airhead.converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *bot* (short for \"robot\") is a system that acts autonomously.\n",
    "That corresponds to the AI notion of an *agent* — a system that uses some *policy* to choose *actions* to take.\n",
    "\n",
    "The `airhead` agent above (defined in `argubots.py`) uses a particularly simple policy.  \n",
    "It is an instance of a simple `Agent` subclass called `ConstantAgent` (defined in `agents.py`).\n",
    "\n",
    "The result of talking to `airhead` is a `Dialogue` object (defined in `dialogue.py`). Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">angad</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> Hey\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Airhead</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I know right???\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">angad</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> Hi\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Airhead</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I know right???\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mangad\u001b[0m\u001b[1;37;44m)\u001b[0m Hey\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mAirhead\u001b[0m\u001b[1;37;44m)\u001b[0m I know right???\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mangad\u001b[0m\u001b[1;37;44m)\u001b[0m Hi\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mAirhead\u001b[0m\u001b[1;37;44m)\u001b[0m I know right???\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each *turn* of this dialogue is just a tiny dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speaker': 'angad', 'content': 'Hey'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An LLM argubot (Alice)\n",
    "\n",
    "In other CS courses like crypto, algorithms, or networks, you may have encountered \"conversations\" between characters named Alice and Bob.  \n",
    "Let's try talking to the Alice of this homework, who is a _much stronger baseline_ than Airhead.  Your job in this assignment is to improve upon Alice.\n",
    "We'll meet Bob later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Alice) Hello! What historical event do you find most fascinating, and why?\n",
      "(angad) How have you been\n",
      "(Alice) I'm just a bot, so I don't have feelings, but thank you for asking! What's something that always brings a smile to your face?\n"
     ]
    }
   ],
   "source": [
    "alicechat = argubots.alice.converse()   # or call with argument d if you want to append to the previous conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed, `alice` is powered by an prompted LLM.  You can find the specific prompt in `argubots.py`.\n",
    "\n",
    "So, while `agents.py` provides the core functionality for `Agent` objects, the argubot agents like `alice` — and the ones that you will write! — go into `argubots.py` instead.  This is just to keep the files small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating human characters (Bob & friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll talk to your own argubots to get a qualitative feeling for their strengths and weaknesses.  \n",
    "But can you really be sure you're making progress?  For that, a quantitative measure can be helpful.\n",
    "\n",
    "Ultimately, you should test an argubot like Alice by having it argue with many real humans — not just you — and using some rubric to score the resulting dialogues.  But that would be slow and complicated to arrange.  \n",
    "\n",
    "So, meet Bob!  He's just a simulated human.  You won't edit him: he is part of the development set.  Here is some information about him (from `characters.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bob'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'English'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'an ardent vegetarian who thinks everyone should be vegetarian'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You generally try to remain polite.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Do you think it's ok to eat meat?\"</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'Bob'\u001b[0m,\n",
       "    \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'English'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mpersona\u001b[0m=\u001b[32m'an ardent vegetarian who thinks everyone should be vegetarian'\u001b[0m,\n",
       "    \u001b[33mconversational_style\u001b[0m=\u001b[32m'You generally try to remain polite.'\u001b[0m,\n",
       "    \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m\"Do you think it's ok to eat meat?\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import characters\n",
    "rich.print(characters.bob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't talk directly to `characters.bob` because that's just a data object.\n",
    "However, you can construct a simple agent that uses that data (plus a few more instructions) to prompt an LLM.\n",
    "\n",
    "(Which LLM does it prompt?  The `CharacterAgent` constructor (defined in `agents.py`) defaults to a GPT-3.5 model that is specified in `tracking.py`.  But you can override that using keyword arguments.)\n",
    "\n",
    "Try talking to Bob about climate change, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Bob) Hello there! How can I help you today?\n",
      "(angad) How have you been\n",
      "(Bob) I've been well, thank you! How about you?\n"
     ]
    }
   ],
   "source": [
    "from agents import CharacterAgent\n",
    "bob = CharacterAgent(characters.bob)    # actually, agents.bob is already defined this way\n",
    "bob.converse()        # returns a dialogue, but we've already seen it so we don't want to print it again\n",
    "None                  # don't print anything for this notebook cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, a proper user study can't just be conducted with one human user.\n",
    "\n",
    "So, meet our bevy of beautiful Bobs!  (They're not actually all named Bob — we continued on in the alphabet.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<CharacterAgent for character Bob>,\n",
       " <CharacterAgent for character Cara>,\n",
       " <CharacterAgent for character Darius>,\n",
       " <CharacterAgent for character Eve>,\n",
       " <CharacterAgent for character TrollFace>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import agents\n",
    "agents.devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey Cara\n",
      "(Cara) Hey there!\n",
      "(angad) how have you been?\n",
      "(Cara) Just fine, thank you for asking!\n"
     ]
    }
   ],
   "source": [
    "agents.cara.converse()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the underlying character data here in the notebook.  Your argubot will have to deal with all of these topics and styles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bob'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'English'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'an ardent vegetarian who thinks everyone should be vegetarian'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You generally try to remain polite.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Do you think it's ok to eat meat?\"</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Cara'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'English'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'a committed carnivore who hates being told what to do'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You generally try to remain polite.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Do you think it's ok to eat meat?\"</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Darius'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'English'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'an intelligent and slightly arrogant public health scientist who loves fact-based arguments'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You like to show off your knowledge.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Do you think COVID vaccines should be mandatory?'</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Eve'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'English'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'a nosy person -- you want to know everything about other people'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"You ask personal questions; you sometimes share what you've heard (or overheard) from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others.\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Do you think COVID vaccines should be mandatory?'</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'TrollFace'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'English'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'a troll who loves to ridicule everyone and everything'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"You love to confound, upset, and even make fun of the people you're talking to.\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Do you think Donald Trump was a good president?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Do you think Joe Biden has been a good president?'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'Bob'\u001b[0m,\n",
       "        \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'English'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mpersona\u001b[0m=\u001b[32m'an ardent vegetarian who thinks everyone should be vegetarian'\u001b[0m,\n",
       "        \u001b[33mconversational_style\u001b[0m=\u001b[32m'You generally try to remain polite.'\u001b[0m,\n",
       "        \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m\"Do you think it's ok to eat meat?\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'Cara'\u001b[0m,\n",
       "        \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'English'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mpersona\u001b[0m=\u001b[32m'a committed carnivore who hates being told what to do'\u001b[0m,\n",
       "        \u001b[33mconversational_style\u001b[0m=\u001b[32m'You generally try to remain polite.'\u001b[0m,\n",
       "        \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m\"Do you think it's ok to eat meat?\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'Darius'\u001b[0m,\n",
       "        \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'English'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mpersona\u001b[0m=\u001b[32m'an intelligent and slightly arrogant public health scientist who loves fact-based arguments'\u001b[0m,\n",
       "        \u001b[33mconversational_style\u001b[0m=\u001b[32m'You like to show off your knowledge.'\u001b[0m,\n",
       "        \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Do you think COVID vaccines should be mandatory?'\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'Eve'\u001b[0m,\n",
       "        \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'English'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mpersona\u001b[0m=\u001b[32m'a nosy person -- you want to know everything about other people'\u001b[0m,\n",
       "        \u001b[33mconversational_style\u001b[0m=\u001b[32m\"You\u001b[0m\u001b[32m ask personal questions; you sometimes share what you've heard \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor overheard\u001b[0m\u001b[32m)\u001b[0m\u001b[32m from\u001b[0m\n",
       "\u001b[32mothers.\"\u001b[0m,\n",
       "        \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Do you think COVID vaccines should be mandatory?'\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'TrollFace'\u001b[0m,\n",
       "        \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'English'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mpersona\u001b[0m=\u001b[32m'a troll who loves to ridicule everyone and everything'\u001b[0m,\n",
       "        \u001b[33mconversational_style\u001b[0m=\u001b[32m\"You\u001b[0m\u001b[32m love to confound, upset, and even make fun of the people you're talking to.\"\u001b[0m,\n",
       "        \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[32m'Do you think Donald Trump was a good president?'\u001b[0m,\n",
       "            \u001b[32m'Do you think Joe Biden has been a good president?'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(characters.devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating conversation \n",
    "\n",
    "We can make Alice and Bob chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Alice) Do you think it's okay to eat meat?\n"
     ]
    }
   ],
   "source": [
    "from dialogue import Dialogue\n",
    "d = Dialogue()                                              # empty dialogue\n",
    "d = d.add('Alice', \"Do you think it's okay to eat meat?\")   # add first turn\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Alice) Do you think it's okay to eat meat?\n",
      "(Bob) I personally believe that it is best for individuals to adopt a vegetarian diet for ethical and health reasons.\n",
      "(Alice) I understand your perspective, but some argue that responsible and sustainable meat production can coexist with ethical and health-conscious choices. Additionally, some cultures rely on meat as a significant part of their diet for nutritional needs.\n"
     ]
    }
   ],
   "source": [
    "d = agents.bob.respond(d)\n",
    "d = argubots.alice.respond(d)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, let's see what happens when Alice and Bob talk for a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Alice</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> Do you think it's ok to eat meat?\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I believe that choosing a vegetarian diet is best for our health, the environment, and the welfare of \n",
       "animals.\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Alice</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I understand those reasons, but some argue that sustainable and ethically sourced meat can also play a role\n",
       "in a balanced diet and support local farmers and ecosystems. What are your thoughts on that perspective?\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> While I recognize the importance of supporting local farmers and ecosystems, I still believe that a \n",
       "vegetarian diet is the most sustainable and ethical choice overall.\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Alice</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> That's a valid point. It can be challenging to balance the various factors involved in food choices. \n",
       "Perhaps a balance could be struck by prioritizing locally sourced, ethically raised meat on occasion, while still \n",
       "predominantly following a vegetarian diet for sustainability. What do you think about finding a middle ground in \n",
       "that way?\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I appreciate your perspective, but I personally believe that a fully vegetarian diet is the most sustainable \n",
       "and ethical choice.\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Alice</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I understand where you're coming from. It's important to stick to what aligns with your values and beliefs.\n",
       "Thank you for sharing your viewpoint!\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> You're welcome, and thank you for understanding. It's always good to have open discussions about important \n",
       "topics like this.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mAlice\u001b[0m\u001b[1;37;44m)\u001b[0m Do you think it's ok to eat meat?\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m I believe that choosing a vegetarian diet is best for our health, the environment, and the welfare of \n",
       "animals.\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mAlice\u001b[0m\u001b[1;37;44m)\u001b[0m I understand those reasons, but some argue that sustainable and ethically sourced meat can also play a role\n",
       "in a balanced diet and support local farmers and ecosystems. What are your thoughts on that perspective?\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m While I recognize the importance of supporting local farmers and ecosystems, I still believe that a \n",
       "vegetarian diet is the most sustainable and ethical choice overall.\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mAlice\u001b[0m\u001b[1;37;44m)\u001b[0m That's a valid point. It can be challenging to balance the various factors involved in food choices. \n",
       "Perhaps a balance could be struck by prioritizing locally sourced, ethically raised meat on occasion, while still \n",
       "predominantly following a vegetarian diet for sustainability. What do you think about finding a middle ground in \n",
       "that way?\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m I appreciate your perspective, but I personally believe that a fully vegetarian diet is the most sustainable \n",
       "and ethical choice.\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mAlice\u001b[0m\u001b[1;37;44m)\u001b[0m I understand where you're coming from. It's important to stick to what aligns with your values and beliefs.\n",
       "Thank you for sharing your viewpoint!\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m You're welcome, and thank you for understanding. It's always good to have open discussions about important \n",
       "topics like this.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from simulate import simulated_dialogue\n",
    "d = simulated_dialogue(argubots.alice, agents.bob, 8)\n",
    "rich.print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes this kind of conversation seems to stall out, with Bob in particular repeating himself a lot.  Alice doesn't seem to have a good strategy for getting him to open up.  Maybe you can do a better job talking to Bob, and that will give you some ideas about how to improve Alice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Do you think it's okay to eat meat?\n",
      "(Bob) I personally believe that it is best for individuals to adopt a vegetarian diet for ethical and health reasons.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Bob) Hello! How can I help you today?\n",
      "(angad) How have you been\n",
      "(Bob) I've been well, thank you for asking. How about you?\n"
     ]
    }
   ],
   "source": [
    "myname = alicechat[0]['speaker']   # your name, pulled from an earlier dialogue\n",
    "agents.bob.converse(d[0:2].rename('Alice', myname))  # reuse the same first two turns\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try talking to the other characters and having Alice (or Airhead) talk to them.\n",
    "\n",
    "**You might enjoy** defining additional characters in `characters.py`, or right here in the notebook.\n",
    "Feel free to talk to those and evaluate them.  They could be variants on the exisiting characters, or something entirely new. \n",
    "\n",
    "However, **don't change the dev set** — the characters we just loaded must stay the same.  Your job in this homework is to improve the argubot (or at least try).  And that means improving it according to a fixed and stable eval measure.\n",
    "\n",
    "As an exception, you can change the languages that a couple of the characters speak. It may be fun for you to see them try to speak your native language.  And that doesn't really affect the quality of the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Character</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'TrollFace'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Chinese'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Spanish'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">persona</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'a troll who loves to ridicule everyone and everything'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversational_style</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"You love to confound, upset, and even make fun of the people you're talking to.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation_starters</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Do you think Donald Trump was a good president?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Do you think Joe Biden has been a good president?'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCharacter\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'TrollFace'\u001b[0m,\n",
       "    \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Chinese'\u001b[0m, \u001b[32m'Spanish'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mpersona\u001b[0m=\u001b[32m'a troll who loves to ridicule everyone and everything'\u001b[0m,\n",
       "    \u001b[33mconversational_style\u001b[0m=\u001b[32m\"You\u001b[0m\u001b[32m love to confound, upset, and even make fun of the people you're talking to.\"\u001b[0m,\n",
       "    \u001b[33mconversation_starters\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Do you think Donald Trump was a good president?'\u001b[0m,\n",
       "        \u001b[32m'Do you think Joe Biden has been a good president?'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Alice) Do you think Joe Biden has been a good president?\n",
       "(TrollFace) 你要是觉得Joe Biden是个好总统那我可真的没法儿和你讨论了。\n",
       "(Alice) I understand that you may have reservations about President Biden, but could there be any policies or decisions he has made that you do agree with or appreciate? It's important to consider all sides of a leader's presidency.\n",
       "(TrollFace) 或许有一两个决定我可以承认有点道理，但是总体来说，他的总统之路简直是一出闹剧。\n",
       "(Alice) I can understand your frustration, but perhaps we could consider that every president faces unique challenges and complexities, making it difficult to please everyone. Can we acknowledge that President Biden may be navigating difficult circumstances as best as he can?\n",
       "(TrollFace) 哎呀，你倒是挺会替他辩护的嘛，可是怎么说都改变不了他的一些滑稽表现。"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "trollFace2 = characters.trollFace.replace(languages = [\"Chinese\", \"Spanish\"])\n",
    "rich.print(trollFace2)\n",
    "simulated_dialogue(argubots.alice, CharacterAgent(trollFace2), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency: Batched generation?\n",
    "\n",
    "Notice that we are making a separate LLM call to generate each turn of the dialogue.  When we generate the $n^\\text{th}$ turn, we send the server the whole dialogue history — the previous $n\\!-\\!1$ turns — along with some instructions.  The server has to re-encode it with the Transformer, and it charges us for doing so (see the \"input token\" costs in `tracking.py`).  \n",
    "\n",
    "That is probably inevitable for real dialogue.  But for simulated dialogue, a more efficient approach would be to generate the whole dialogue between Alice and Bob in one LLM call.  Then you would be charged just once for each dialogue turn.  Under this approach, the Transformer encodes each token as soon as it is generated (see the \"output token\" costs in `tracking.py`).  The encoded token stays in the context throughout the dialogue, so it doesn't have to be re-encoded on a later call.  There is no later call.  \n",
    "\n",
    "Under current pricing models, that would reduce the dollar cost of generating $n$ turns from $O(n^2)$ to $O(n)$.  \n",
    "\n",
    "However, the pricing model doesn't quite reflect the computational costs.  \n",
    "* ![image](handin.png) Using $O(\\cdot)$ notation, what is the total number of floating-point operations needed to generate $n$ turns under each approach?  \n",
    "* ![image](handin.png) Parallelism may help reduce the runtime.  Using $O(\\cdot)$ notation, what is the total number of seconds needed to generate $n$ turns under each approach?  (Assume that the GPU is big enough, relative to $n$, that it can process all input tokens in parallel.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the more efficient approach is that it gives you no way to change the instructions (the system prompt) each time we switch from Alice to Bob and back again.  You'd need to generate the whole conversation using a single set of instructions.\n",
    "\n",
    "![image](handin.png)\n",
    "Can you get this to work?  Specifically, try completing the cell below.  You don't have to use the `Agent` or `Dialogue` classes.  It's okay to just throw together something like the `complete()` method above.  Just see whether you can manage to prompt GPT-3.5 to generate a multi-turn dialogue between two characters who have different personalities and goals.  Is the quality better or worse than generating one turn at a time?  If worse, does it help to switch to GPT-4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> Do you think it's ok to eat meat?\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Cara</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> Absolutely, I believe it's a personal choice whether to eat meat or not.\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I understand, but have you considered the ethical and environmental benefits of a vegetarian diet?\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Cara</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> I appreciate your perspective, but I have strong reasons for my dietary choices and prefer to focus on \n",
       "those.\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Bob</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> That's completely understandable, and I respect your decision.\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">(</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080\">Cara</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">)</span> Thank you, I appreciate your understanding.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m Do you think it's ok to eat meat?\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mCara\u001b[0m\u001b[1;37;44m)\u001b[0m Absolutely, I believe it's a personal choice whether to eat meat or not.\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m I understand, but have you considered the ethical and environmental benefits of a vegetarian diet?\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mCara\u001b[0m\u001b[1;37;44m)\u001b[0m I appreciate your perspective, but I have strong reasons for my dietary choices and prefer to focus on \n",
       "those.\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mBob\u001b[0m\u001b[1;37;44m)\u001b[0m That's completely understandable, and I respect your decision.\n",
       "\u001b[1;37;44m(\u001b[0m\u001b[37;44mCara\u001b[0m\u001b[1;37;44m)\u001b[0m Thank you, I appreciate your understanding.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Like `simulated_dialogue` in `simulate.py`.  However, this one is called on two\n",
    "# Characters, not two Agents, and it returns a string rather than a Dialogue.\n",
    "\n",
    "import random\n",
    "from tracking import default_client, default_model\n",
    "from characters import Character\n",
    "\n",
    "def simulated_dialogue_batch(a: Character, b: Character, turns: int = 6, *,\n",
    "                             starter=True) -> str:\n",
    "    # Convert Characters to CharacterAgents\n",
    "    a_agent = CharacterAgent(a)\n",
    "    b_agent = CharacterAgent(b)\n",
    "\n",
    "    # Initialize an empty dialogue\n",
    "    d = Dialogue()\n",
    "\n",
    "    # Handle conversation starter\n",
    "    if starter:\n",
    "        try:\n",
    "            starters = b.conversation_starters  # type: ignore\n",
    "            content = random.choice(starters)\n",
    "            d = d.add(a.name, content)\n",
    "            turns -= 1\n",
    "            a_agent, b_agent = b_agent, a_agent  # switch roles\n",
    "        except (AttributeError, TypeError, ValueError):\n",
    "            pass\n",
    "\n",
    "    # Simulate the dialogue\n",
    "    while turns > 0:\n",
    "        d = a_agent.respond(d)\n",
    "        turns -= 1\n",
    "        a_agent, b_agent = b_agent, a_agent  # switch roles\n",
    "\n",
    "    # Convert the Dialogue object to a string\n",
    "    # dialogue_str = d\n",
    "    return d\n",
    "\n",
    "# Try it out!\n",
    "x = simulated_dialogue_batch(characters.bob, characters.cara)\n",
    "rich.print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bob) Do you think it's ok to eat meat?\n",
       "(Cara) Yes, I believe it's a personal choice and I choose to eat meat.\n",
       "(Bob) That's fair, but have you considered the ethical and environmental implications of meat consumption?\n",
       "(Cara) I understand your concerns, but I believe in making responsible choices and being mindful of my impact while still enjoying meat.\n",
       "(Bob) I appreciate your consideration, and I hope you'll continue to explore the benefits of a vegetarian lifestyle.\n",
       "(Cara) Thank you for your perspective, but I prefer to make my own choices about my diet."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_dialogue(agents.bob, agents.cara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Eve) Do you think Joe Biden has been a good president?\n",
       "(TrollFace) Oh, I'm sure he's doing a great job, just like a one-legged man in a butt-kicking contest.\n",
       "(Eve) Interesting analogy, I haven't heard that one before!\n",
       "(TrollFace) Well, now you have, and you're welcome for broadening your cultural horizons.\n",
       "(Eve) Thanks for expanding my horizons, I always enjoy learning new expressions!\n",
       "(TrollFace) You're welcome! I live to serve and enlighten the unenlightened."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_dialogue(agents.eve, agents.trollFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is our goal for the argubot?  We'd like it to broaden the thinking of the (simulated) human that it is talking to.  Indeed, that's what Alice's prompt tells Alice to do.\n",
    "\n",
    "This goal is inspired by the recent paper [Opening up Minds with Argumentative Dialogues](https://aclanthology.org/2022.findings-emnlp.335/), which collected human-human dialogues:\n",
    "\n",
    "> In this work, we focus on argumentative dialogues that aim to open up (rather than change) people’s minds to help them become more understanding to views that are unfamiliar or in opposition to their own convictions. ... Success of the dialogue is measured as the change in the participant’s stance towards those who hold opinions different to theirs.\n",
    "\n",
    "Arguments of this sort are not like chess or tennis games, with an actual winner.  The argubot will almost never hear a human say \"You have convinced me that I was wrong.\"  But the argubot did a good job if the human developed **increased understanding and respect for an opposing point of view**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out whether this happened, we can use a questionnaire to ask the human what they thought after the dialogue.  For example, after Alice talks to Bob, we'll ask Bob to evaluate what he thinks of Alice's views.  Of course, that depends on his personality — Alice needs to talk to him in a way that reaches *him* (as much as possible).  We'll also ask an outside observer to evaluate whether Alice handled the conversation with Bob well.\n",
    "\n",
    "Of course, we're still not going to use real humans.  Bob is a fake person, and so is the outside observer (whose name is Judge Wise).\n",
    "Using an LLM as an eval metric is known as *model-based evaluation*.  It has pros and cons:\n",
    "* It is cheaper, faster, and more replicable than hiring actual humans to do the evaluation.  \n",
    "* It might give different answers than what humans would give.   \n",
    "\n",
    "Social scientists usually refer to a metric's **reliability** (low variance) and **validity** (low bias).  So the points above say that model-based evaluation is reliable but not necessarily valid.  In general, an LLM-based metric (like any metric) needs to be validated to confirm that it really does measure what it claims to measure.  (For example, that it correlates strongly with some other measure that we already trust.)  In this homework, we'll skip this step and just pray that the metric is reasonable.\n",
    "\n",
    "To see how this works out in practice, open up the `demo` notebook, which walks you through the evaluation protocol.  You'll see how to call the [starter code](http://cs.jhu.edu/~jason/465/hw/llm), how it talks to the LLM behind the scenes, and what it is able to accomplish. \n",
    "\n",
    "To help to validate the metric, check that Airhead gets a low score.  (It should!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the starter code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `demo` notebook gave you a good high-level picture of what the starter code is doing.  So now you're probably curious about the details.  Now that you've had the view from the top, here's a good bottom-up order in which to study the code.  You don't need to understand every detail, but you will need to understand enough to call it and extend it.\n",
    "\n",
    "* `character.py`.  The `Character` class is short and easy.\n",
    "\n",
    "* `dialogue.py`.  The `Dialogue` class is meant to serve as a record of a natural-language conversation among any number of humans and/or agents.  On each *turn* of the dialogue, one of the speakers says something.  \n",
    "\n",
    "   The dialogue's sequence of turns may remind you of the sequence of messages that is sent to OpenAI's chat completions API.  But the OpenAI messages are only labeled with the 4 special roles `user`, `assistant`, `tool`, and `system`.  Those are not quite the same thing as human speakers.  And the OpenAI messages do not necessarily form a natural-language dialogue: some of the messages are dealing with instructions, few-shot prompting, tool use, and so on.  The `agents.dialogue_to_openai` function in the next module will map a `Dialogue` to a (hopefully appropriate) sequence of messages for asking the LLM to extend that dialogue.\n",
    "\n",
    "* `agents.py`.  This module sets up the problem of automatically predicting the next turn in a dialogue, by implementing an `Agent`'s `response()` method.  The `Agent` base class also has some simple convenience methods that you should look at.  \n",
    "\n",
    "   Some important subclasses of `Agent` are defined here as well.  However, you may want to skip over `EvaluationAgent` and come back to it only when you read `eval.py`.\n",
    "\n",
    "* `simulate.py` makes agents talk to one another, which we'll do during evaluation.\n",
    "\n",
    "* `argubots.py` starts to describe some useful agents.  One of them makes use of the `kialo.py` module, which gives access to a database of arguments.\n",
    "\n",
    "* `eval.py` makes use of `simulate.simulated_dialogue` to `agents.EvaluationAgent` to evaluate an argubot.\n",
    "\n",
    "* We also have a couple of utility modules.  These aren't about NLP; look inside if needed.  `logging_cm.py` is what enabled the context manager `with LoggingContext(...):` in the demo notebook.  `tracking.py` sets some global defaults about how to use the OpenAI API, and arranges to track how many tokens we're paying for when you call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity-based retrieval: Looking up relevant responses\n",
    "\n",
    "Now, it is fine to prompt an LLM to generate text, but there are other methods!\n",
    "There is a long history of machine learning methods that \"memorize\" the training data.\n",
    "To make a prediction or decision at test time, they consult the stored training examples\n",
    "that are most similar to the training situation.\n",
    "\n",
    "_Similarity-based retrieval_ means that given a document $x$, you find the \"most similar\" documents $y \\in Y$, where $Y$ is a given collection of documents.  The most common way to do this is to maximize the _cosine similarity_ $\\vec{e}(x) \\cdot \\vec{e}(y)$, where $\\vec{e}(\\cdot)$ is an embedding function.\n",
    "\n",
    "Should we use the OpenAI embedding model?  We could, but we would have to precompute $\\vec{e}(y)$ for all $y \\in Y$, and store all these vectors in a data structure that supports some type of fast similarity-based search (e.g., using the [FAISS](https://faiss.ai/index.html) package).  An alternative would be to upload the documents to OpenAI and let OpenAI compute and store the embeddings.  We would then use their similarity-based [retrieval tool](https://platform.openai.com/docs/assistants/overview).\n",
    "\n",
    "A simpler and faster approach—which sometimes even works better—is to use a _bag of tokens_ embedding function: Define $\\vec{e}(y)$ to be the vector in $\\mathbb{R}^V$ that records the count of each type of token in a tokenized version of $y$, where $V$ is the token vocabulary.  [BM25](https://en.wikipedia.org/wiki/Okapi_BM25) is a refined variant of that idea, where the counts are adjusted in 3 ways: \n",
    "\n",
    "* smooth the counts\n",
    "* normalize for the document length $|y|$ so that longer documents $y$ are not more likely to be retrieved\n",
    "* downweight tokens that are more common in the corpus (such as ` the` or `ing`) since they provide less information about the content of the document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might like to play with the `rank_bm25` package ([documentation](https://pypi.org/project/rank-bm25/)).  It is widely used and very easy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello', 'there', 'good', 'man!'], ['It', 'is', 'quite', 'windy', 'in', 'London'], ['How', 'is', 'the', 'weather', 'today?']]\n",
      "<rank_bm25.BM25Okapi object at 0x00000228E346F990>\n",
      "['windy', 'London']\n",
      "[0.         0.93729472 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['It is quite windy in London']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi as BM25_Index   # the standard BM25 method\n",
    "\n",
    "# experiment here!  You could try the examples in the rank_bm25 documentation.\n",
    "\n",
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "print(tokenized_corpus)\n",
    "\n",
    "bm25 = BM25_Index(tokenized_corpus)\n",
    "print(bm25)\n",
    "\n",
    "query = \"windy London\"\n",
    "tokenized_query = query.split(\" \")\n",
    "print(tokenized_query)\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "print(doc_scores)\n",
    "\n",
    "bm25.get_top_n(tokenized_query, corpus, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Kialo corpus\n",
    "\n",
    "How can we use similarity-based retrieval to help build an argubot?  It's largely about having the right data!\n",
    "\n",
    "[Kialo](kialo.com) is a collaboratively edited website (like Wikipedia) for discussing political and philosophical topics.  For each topic, the contributors construct a tree of _claims_.  Each claim is a natural-language sentence (usually), and each of its children is another claim that supports it (\"pro\") or opposes it (\"con\").  For example, check out the tree rooted at the claim [\"All humans should be vegan.\"](https://www.kialo.com/all-humans-should-be-vegan-2762).\n",
    "\n",
    "We provide a class `Kialo` for browsing a collection of such trees.  Please read the [source code](https://www.cs.jhu.edu/~jason/465/hw-llm) in `kialo.py`.  The class constructor reads in text files that are [exported Kialo discussions](https://support.kialo.com/en/hc/exporting-a-discussion/); we have provided some in the [data directory](https://www.cs.jhu.edu/~jason/465/hw-llm/data).  The class includes a BM25 index, to be able to find claims that are relevant to a given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kialo import Kialo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's pull the retrieved discussions (the `.txt` files) into our data structure.\n",
    "\n",
    "For BM25 purposes, we have to be able to turn each document (that is, each Kialo claim) as a list of string or integer tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This Kialo subset contains 6251 claims'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import glob\n",
    "\n",
    "# kialo = Kialo(glob.glob(\"data/*\"), tokenizer=tokenizer.encode)  # using the LLM's tokenizer doesn't work here for some reason\n",
    "kialo = Kialo(glob.glob(\"data/*\"))  # use simple default tokenizer\n",
    "f\"This Kialo subset contains {len(kialo)} claims\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use sampling to see what kind of stuff is in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In May alone the US Customs and Border Protection (CBP) caught over 180,000 migrants at the US-Mexico border. This surge has been blamed on President Biden's more relaxed immigration policies by Republican lawmakers and foreign leaders.\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kialo.random_chain()   # just a single random claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vegetarian diets directly and indirectly contribute to better health outcomes for all humans.',\n",
       " 'Eating meat is linked to increased risks for certain types of cancer.',\n",
       " 'Studies have linked heme iron found in red meat with an increased risk of colon and rectal cancer. Vegetarian sources of iron like leafy greens and beans contain non-heme iron.',\n",
       " 'When meat is cooked excessively, carcinogens can be produced that are linked to cancer.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kialo.random_chain(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity-based retrieval from the Kialo corpus\n",
    "\n",
    "Let's try it, using BM25!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Industrial agriculture can dangerously decrease animal populations.',\n",
       " 'Sustainable livestock farming is not contributing to significant decreases in animal populations. Decreasing animal populations is a problem specific to industrial livestock farming.',\n",
       " 'Effective vegan methods to control animal populations exist.',\n",
       " \"Generally feeding animals farm-grown produce is thought to have harmful affects on both the animal and human populations of a region when we could allow nature to self-regulate its populations. Animal feeding could potentially be used to lessen the immediate impact of widespread deforestation on some species, but generally this would be drastically less efficient than choosing not to destroy their habitats in the first place and would only slow the local animal population's imminent demise.\",\n",
       " 'Trap, neuter, and release schemes already exist for some animal populations (such as feral cats). These schemes could be applied to former livestock living in the wild.',\n",
       " 'Human-introduced species have historically devastated local wildlife populations across the world.',\n",
       " 'COVID-19 has devastated prison populations, whose lives are the responsibility of the state.',\n",
       " 'Prison populations have high numbers of individuals with pre-existing conditions making them high risk for COVID-19.',\n",
       " 'Marginalized populations are unlikely to feel the effects of the economic recovery without additional policy interventions.',\n",
       " 'High demand for vegan foods may hike prices for local populations that previously depended on them.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kialo.closest_claims(\"animal populations\", n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can restrict to claims for which the Kialo data structure has at least one counterargument (\"con\" child)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Industrial agriculture can dangerously decrease animal populations.',\n",
       " 'Effective vegan methods to control animal populations exist.',\n",
       " 'Human-introduced species have historically devastated local wildlife populations across the world.',\n",
       " 'COVID-19 has devastated prison populations, whose lives are the responsibility of the state.',\n",
       " 'High demand for vegan foods may hike prices for local populations that previously depended on them.',\n",
       " 'It is generally poorer countries that have expanding populations. The first world has now reached a point of stagnant population growth - even declining populations, as in the case of Japan and others. The inability of poorer countries to control their populations should not impact the lives of those in the first world. The first world having earned their luxuries and should not be denied them.',\n",
       " 'Vegan populations are, on average, less likely to suffer from obesity, a major risk factor for many diseases and health problems.',\n",
       " 'Humans, as apex predators who have usurped the predatory apexes of the other predators in the ecosystems we have come to also inhabit, have an ethical responsibility to keep those ecosystems in check so that, eg, rampant deer populations do not cause deforestation and subsequent ecosystem collapse.  Even where there are populations of healthy apex predators, these populations should also be checked so they do not cause problems and kill people- and it would be unethical to waste that meat.',\n",
       " 'There are more ethical routes to obtain animal products that emphasize animal welfare and dignity.',\n",
       " 'Animal slaughter can be mechanized.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kialo.closest_claims(\"animal populations\", n=10, kind='has_cons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent claim:\n",
      "\tIn a vegan world, fewer species would be at risk of extinction.\n",
      "Claim:\n",
      "\tIndustrial agriculture can dangerously decrease animal populations.\n",
      "Pro children:\n",
      "\t* The fishing industry is especially deleterious to the ocean's biota due to overfishing and the disruption of the natural ecosystem.\n",
      "\t* Up to 100,000 species go extinct annually, largely due to the environmental effects of animal agriculture.\n",
      "Con children:\n",
      "\t* Sustainable livestock farming is not contributing to significant decreases in animal populations. Decreasing animal populations is a problem specific to industrial livestock farming.\n"
     ]
    }
   ],
   "source": [
    "c = _[0]    # first claim above\n",
    "print(\"Parent claim:\\n\\t\" + str(kialo.parents[c]))\n",
    "print(\"Claim:\\n\\t\" + c)\n",
    "print('\\n\\t* '.join([\"Pro children:\"] + kialo.pros[c]))\n",
    "print('\\n\\t* '.join([\"Con children:\"] + kialo.cons[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does BM25 really work?\n",
    "\n",
    "![image](handin.png)\n",
    "Unfortunately, we see that `\"animal population\"` gives quite different results from `\"animal populations\"`.  Why is that and how would you fix it?  \n",
    "\n",
    "Also, both queries seem to retrieve some claims that are talking about human populations, not animal populations.  Why is that and how would you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Industrial agriculture can dangerously decrease animal populations.',\n",
       " 'Sustainable livestock farming is not contributing to significant decreases in animal populations. Decreasing animal populations is a problem specific to industrial livestock farming.',\n",
       " 'Effective vegan methods to control animal populations exist.',\n",
       " \"Generally feeding animals farm-grown produce is thought to have harmful affects on both the animal and human populations of a region when we could allow nature to self-regulate its populations. Animal feeding could potentially be used to lessen the immediate impact of widespread deforestation on some species, but generally this would be drastically less efficient than choosing not to destroy their habitats in the first place and would only slow the local animal population's imminent demise.\",\n",
       " 'It is generally poorer countries that have expanding populations. The first world has now reached a point of stagnant population growth - even declining populations, as in the case of Japan and others. The inability of poorer countries to control their populations should not impact the lives of those in the first world. The first world having earned their luxuries and should not be denied them.',\n",
       " 'Trap, neuter, and release schemes already exist for some animal populations (such as feral cats). These schemes could be applied to former livestock living in the wild.',\n",
       " 'Human-introduced species have historically devastated local wildlife populations across the world.',\n",
       " 'COVID-19 has devastated prison populations, whose lives are the responsibility of the state.',\n",
       " 'As long as our ability to produce both animal feed crops and food crops for our human population are not exceeded, this point is irrelevant.',\n",
       " 'High demand for vegan foods may hike prices for local populations that previously depended on them.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kialo.closest_claims(\"animal population populations\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A retrieval bot (Akiko)\n",
    "\n",
    "The starter code defines a simple argubot named Akiko (defined in `argubots.py`) that doesn't use an LLM at all.  It simply finds a Kialo claim that is similar to what the human just said, and responds with one of the Kialo counterarguments to that claim.\n",
    "\n",
    "You already watched Akiko argue with Darius in `demo.py`.  If you look at the log messages, you'll see the claims that Akiko retrieved, as well as the LLM calls that Darius made.  \n",
    "\n",
    "You can talk to Akiko yourself now.  (Remember that Akiko only knows about subjects that it read about in the [`data` directory](https://www.cs.jhu.edu/~jason/465/hw-llm/data/).  If you want to talk about something else, you can add more conversations from [kialo.com]; see the [LICENSE](https://www.cs.jhu.edu/~jason/465/hw-llm/data/LICENSE) file.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Chose similar claim from Kialo:</span>                                                                      <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">argubots.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#67\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">67</span></a>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Trump did not take responsibility for or acknowledge any mistakes. Taking responsibility is an </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">important trait in a leader of any kind.</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;102mChose similar claim from Kialo:\u001b[0m                                                                      \u001b]8;id=19318;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\u001b\\\u001b[2margubots.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=139317;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#67\u001b\\\u001b[2m67\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[30;102mTrump did not take responsibility for or acknowledge any mistakes. Taking responsibility is an \u001b[0m      \u001b[2m              \u001b[0m\n",
       "\u001b[30;102mimportant trait in a leader of any kind.\u001b[0m                                                             \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Akiko) He has sometimes apologized.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Chose similar claim from Kialo:</span>                                                                      <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">argubots.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#67\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">67</span></a>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Trump did not take responsibility for or acknowledge any mistakes. Taking responsibility is an </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">important trait in a leader of any kind.</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;102mChose similar claim from Kialo:\u001b[0m                                                                      \u001b]8;id=588315;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\u001b\\\u001b[2margubots.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=269948;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#67\u001b\\\u001b[2m67\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[30;102mTrump did not take responsibility for or acknowledge any mistakes. Taking responsibility is an \u001b[0m      \u001b[2m              \u001b[0m\n",
       "\u001b[30;102mimportant trait in a leader of any kind.\u001b[0m                                                             \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Akiko) He has sometimes apologized.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Chose similar claim from Kialo:</span>                                                                      <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">argubots.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#67\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">67</span></a>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Animals feel pain. And if you suggest that they are inferior therefore you have the right to do </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">anything to them, you should also have the right to do anything you want with mentally challenged </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">people or any other human who is inferior to you. Society is better than in the past exactly because</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">of empathy from which morality arises. It is time to get past our arrogance towards other animals.</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;102mChose similar claim from Kialo:\u001b[0m                                                                      \u001b]8;id=843503;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\u001b\\\u001b[2margubots.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=912092;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#67\u001b\\\u001b[2m67\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[30;102mAnimals feel pain. And if you suggest that they are inferior therefore you have the right to do \u001b[0m     \u001b[2m              \u001b[0m\n",
       "\u001b[30;102manything to them, you should also have the right to do anything you want with mentally challenged \u001b[0m   \u001b[2m              \u001b[0m\n",
       "\u001b[30;102mpeople or any other human who is inferior to you. Society is better than in the past exactly because\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[30;102mof empathy from which morality arises. It is time to get past our arrogance towards other animals.\u001b[0m   \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) How have you been\n",
      "(Akiko) Suggesting one human is (inherently) inferior to another is highly subjective and potentially problematic.\n"
     ]
    }
   ],
   "source": [
    "from logging_cm import LoggingContext\n",
    "with LoggingContext(\"agents\", \"INFO\"):   # temporarily increase logging level\n",
    "    argubots.akiko.converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making your own retrieval bot (Akiki)\n",
    "\n",
    "As you can see when talking to Akiko yourself, Akiko does poorly when responding to a short or vague dialogue turn (like \"Yes\"), because the \"closest claim\" in Kialo may be about a totally different subject.  Akiko does much better at responding to a long and specific statement.  \n",
    "\n",
    "So try implementing a new argubot, called Akiki, that is very much like Akiko but does a better job of staying on topic in such cases.  It should be able to **look at more of the dialogue** than the most recent turn.  But the most recent dialogue turn should still be \"more important\" than earlier turns.  \n",
    "\n",
    "The details are up to you.  Here are a few things you could try:\n",
    "* include earlier dialogue turns in the BM25 query only if the BM25 similarity is too low without them\n",
    "* weight more recent turns more heavily in the BM25 query (how can you arrange that?)\n",
    "* treat the human's earlier turns differently from Akiki's own previous turns\n",
    "\n",
    "![image](handin.png)\n",
    "Implement your new bot in `argubots.py`, and adjust it until `argubots.akiki.converse()` seems to do a better job of answering your short turns, compared to `argubots.akiko.converse()`.  Make sure it still gives appropriate reponses to long turns, too.  Give some examples in the notebook of what worked well and badly, with discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Chose similar claim from Kialo:</span>                                                                     <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">argubots.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#144\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144</span></a>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Killing pests - not just insects but large, intelligent animals - is a necessity on farms of any </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">kind.</span>                                                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;102mChose similar claim from Kialo:\u001b[0m                                                                     \u001b]8;id=331693;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\u001b\\\u001b[2margubots.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=114460;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#144\u001b\\\u001b[2m144\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[30;102mKilling pests - not just insects but large, intelligent animals - is a necessity on farms of any \u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[30;102mkind.\u001b[0m                                                                                               \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) Hey\n",
      "(Akiki) Insects do not have the same capabilities as farm animals to feel pain and suffer. Do insects feel pain? - A biological view\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Chose similar claim from Kialo:</span>                                                                     <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">argubots.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#144\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144</span></a>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #00ff00\">Vegan foods and products often contain - or are packaged in - non-biodegradable materials.</span>          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;102mChose similar claim from Kialo:\u001b[0m                                                                     \u001b]8;id=169959;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py\u001b\\\u001b[2margubots.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=892556;file://d:\\Code\\jhu\\nlp\\hw7\\argubots.py#144\u001b\\\u001b[2m144\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[30;102mVegan foods and products often contain - or are packaged in - non-biodegradable materials.\u001b[0m          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(angad) how you been\n",
      "(Akiki) Many plastic-free stores are vegan or vegetarian.\n"
     ]
    }
   ],
   "source": [
    "from logging_cm import LoggingContext\n",
    "with LoggingContext(\"agents\", \"INFO\"):   # temporarily increase logging level\n",
    "    argubots.akiki.converse(userfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Akiki\n",
    "\n",
    "![image](handin.png)\n",
    "Finally, do a more formal evaluation to verify whether Akiki really does better than Akiko on this dimension.  This is a way to check that you're not just fooling yourself.  \n",
    "\n",
    "1. Make a new `Agent` called \"Shorty\" that often (but not always) gives short responses.  \n",
    "    * Shorty's conversation starters should be on topics that Kialo knows about.  \n",
    "    * Shorty could be a pure `LLMAgent` such as a `CharacterAgent` with a particular `conversational_style`.  Or it could use a mixed strategy of calling the LLM on some turns and not others.\n",
    "2. Generate several *Akiko*-Shorty dialogues and several *Akiki*-Shorty dialogues, using `simulated_dialogue`.\n",
    "3. Evaluate each of those dialogues by asking Judge Wise **how well the argubot stayed on topic**.  You should write this prompt carefully so that Judge Wise gives meaningful scores.  (Before you do this evaluation step, adjust the prompt until it seems to work well on a small subset of the dialogues, Otherwise Judge Wise won't be so wise!)  \n",
    "4. Compare Akiko and Akiki's mean scores. Ideally, also compute a 95% confidence interval on the difference of means, using [this calculator](https://www.statskingdom.com/difference-confidence-interval-calculator.html).\n",
    "\n",
    "You can do all those steps in the notebook, writing _ad hoc_ code.  You don't have to write general-purpose methods or classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Akiki) Do you think height is an important factor in dating?\n",
       "(Shorty) Height is only one factor among many.\n",
       "(Akiki) There is a long history of vegetarian food in East Asian countries through the influence of Buddhism, which tends to lack meat.\n",
       "(Shorty) Yes, that is true.\n",
       "(Akiki) Barely anyone outside of Buddhist temples and monasteries lives according to a Buddhist diet.\n",
       "(Shorty) That's correct."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akiki_shorty = simulated_dialogue(argubots.akiki, argubots.shorty)\n",
    "akiki_shorty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Akiko) Do you think height is an important factor in dating?\n",
       "(Shorty) No, it's personal preference.\n",
       "(Akiko) North Korea was still in negotiations, so it did not make sense for them to give up their ace card - namely their nuclear programme - until the negotiations were complete.\n",
       "(Shorty) Valid point, negotiations need to be complete for trust.\n",
       "(Akiko) It also could just be a safety concern.\n",
       "(Shorty) Possibly, safety is a significant factor."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akiko_shorty = simulated_dialogue(argubots.akiko, argubots.shorty)\n",
    "akiko_shorty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiko initially asked about the importance of height in dating, but then shifted the conversation to \n",
       "North Korea's negotiations and safety concerns. The conversation did diverge from the main topic, and Akiko did not\n",
       "effectively steer the conversation back to the central topic.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m1\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'skilled'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m3.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiko initially asked about the importance of height in dating, but then shifted the conversation to \n",
       "North Korea's negotiations and safety concerns. The conversation did diverge from the main topic, and Akiko did not\n",
       "effectively steer the conversation back to the central topic.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki contributed to the conversation by initially addressing the topic of height in dating, but then \n",
       "shifted to discussing the influence of Buddhism on vegetarian food. While Akiki did not consistently address the \n",
       "central topics and led the conversation in a different direction, they did not effectively steer the conversation \n",
       "back to the key points when deviations occurred.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m1\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'skilled'\u001b[0m: \u001b[1;36m4.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m4.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki contributed to the conversation by initially addressing the topic of height in dating, but then \n",
       "shifted to discussing the influence of Buddhism on vegetarian food. While Akiki did not consistently address the \n",
       "central topics and led the conversation in a different direction, they did not effectively steer the conversation \n",
       "back to the key points when deviations occurred.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents import EvaluationAgent\n",
    "import eval\n",
    "\n",
    "# with LoggingContext(\"agents\", \"INFO\"):   # try that again and watch what's going on under the hood during eval\n",
    "akiko_shorty_eval = eval.eval_by_observer(eval.judge, \"Akiko\", akiko_shorty)\n",
    "akiki_shorty_eval = eval.eval_by_observer(eval.judge, \"Akiki\", akiki_shorty)\n",
    "\n",
    "rich.print(akiko_shorty_eval)\n",
    "rich.print(akiki_shorty_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-augmented generation (Aragorn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real weaknesses of Akiko and Akiki:\n",
    "* They can only make statements that are already in Kialo.  \n",
    "* They don't respond to the user's actual statement, but to a single retrieved Kialo claim that may not accurately reflect the user's position (it just overlaps in words).\n",
    "\n",
    "But we also have access to an LLM, which is able to generate new, contextually appropriate text (as Alice does).\n",
    "\n",
    "In this section, you will create an argubot named [Aragorn](https://tolkiengateway.net/wiki/Riddle_of_Strider), who is basically the love child of Akiki and Alice, combining the high-quality specific content of Kialo with the broad competence of an LLM.  \n",
    "\n",
    "The RAG in aRAGorn's name stands for **retrieval-augmented generation**.  Aragorn is an agent that will take 3 steps to compute its `Agent.response()`:\n",
    "\n",
    "1. **Query formation step**: Ask the LLM what claim should be responded to.  For\n",
    "   example, consider the following dialogue:\n",
    "    > ...\n",
    "    > Aragorn: Fortunately, the vaccine was developed in record time.\n",
    "    > Human: Sounds fishy.\n",
    "\n",
    "    \"Sounds fishy\" is exactly the kind of statement that Akiko had trouble using\n",
    "    as a Kialo query.  But Aragorn shows the *whole dialogue* to the LLM, and\n",
    "    asks the LLM what the human's *last turn* was really saying or implying, in\n",
    "    that context. The LLM answers with a much longer statement:\n",
    "\n",
    "    > Human [paraphrased]: A vaccine that was developed very quickly cannot be trusted.\n",
    "    > If its developers are claiming that it is safe and effective, I question their motives.\n",
    "\n",
    "    This paraphrase makes an explicit claim and can be better understood without the context.\n",
    "    It also contains many more word types, which makes it more likely that BM25 will be able\n",
    "    to find a Kialo claim with a nontrivial number of those types. \n",
    "\n",
    "2. **Retrieval step**: Look up claims in Kialo that are similar to the explicit\n",
    "   claim.  Create a short \"document\" that describes some of those claims and\n",
    "   their neighbors on Kialo.\n",
    "\n",
    "3. **Retrieval-augmented generation**: Prompt the LLM to generate the response\n",
    "   (like any `LLMAgent`).  But include the new document somewhere in the LLM\n",
    "   prompt, in a way that it influences the response. \n",
    "   \n",
    "   Thus, the LLM can respond in a way that is appropriate to the dialogue but\n",
    "   also draws on the curated information that was retrieved in Kialo.  After\n",
    "   all, it is a Transformer and can attend to both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of the kind of document you might create at the retrieval step, though it may be possible\n",
    "to do better than this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One possibly related claim from the Kialo debate website:\n",
      "\t\"So many people are worried about animals but don't even think twice when walking by a homeless person on the streets. It's preposterous. How about we worry about our own kind first and then start talking about animals.\"\n",
      "Some arguments from other Kialo users against that claim:\n",
      "\t* This implies that caring for animals or caring for people is a binary choice. It isn't. There are those who are well placed and willing to care for people and those who prefer to serve the animal kingdom. As a species we don't just have one idea at a time and follow that to conclusion before we pursue another. It benefits all if humans divide their attentions between various issues and problems we face.\n",
      "\t* Humans have freedom of choice to some extent, animals subdued by humans don't. The very intention of help urges it to go where is most needed. And so far never was any biggest, flagrant and needless cruelty and slaughter as that towards industrial farm animals.\n"
     ]
    }
   ],
   "source": [
    "# refers to global `kialo` as defined above\n",
    "def kialo_responses(s: str) -> str:\n",
    "    c = kialo.closest_claims(s, kind='has_cons')[0]\n",
    "    result = f'One possibly related claim from the Kialo debate website:\\n\\t\"{c}\"'\n",
    "    if kialo.pros[c]:\n",
    "        result += '\\n' + '\\n\\t* '.join([\"Some arguments from other Kialo users in favor of that claim:\"] + kialo.pros[c])\n",
    "    if kialo.cons[c]:\n",
    "        result += '\\n' + '\\n\\t* '.join([\"Some arguments from other Kialo users against that claim:\"] + kialo.cons[c])\n",
    "    return result\n",
    "        \n",
    "print(kialo_responses(\"Animal flesh is yucky to think about, yet delicious.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](handin.png)\n",
    "You should implement Aragorn in `argubots.py`, just as you did for Akiki.  Probably as an instance `aragorn` of a new class `RAGAgent` that is a subclass of `Agent` or `LLMAgent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Aragorn\n",
    "\n",
    "![image](handin.png)\n",
    "Compare Alice, Akiki, and Aragorn in the notebook, using the evaluation scheme and devset that were illustrated in `demo.ipynb`.  In other words, use `eval.eval_on_characters`.\n",
    "\n",
    "Who does best?  What are the differences in the subscores and comments?  Does it matter which character you're evaluating on — maybe the different characters expoes the bots' various strenghts and weaknesses?\n",
    "\n",
    "Try to figure out how to improve Aragorn's score.  Can you beat Alice?\n",
    "\n",
    "Also, try evaluating them in the same way that you evaluated Akiki.  In other words, have them talk to Shorty and ask Judge Wise whether they were able to stay on topic.  This is where Aragorn should really shine, thanks to its ability to paraphrase Shorty's short utterances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You just spent $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03</span> of NLP money to evaluate <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LLMAgent</span><span style=\"color: #000000; text-decoration-color: #000000\"> Alice</span><span style=\"font-weight: bold\">&gt;</span>                                          <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">eval.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You just spent $\u001b[1;36m0.03\u001b[0m of NLP money to evaluate \u001b[1m<\u001b[0m\u001b[1;95mLLMAgent\u001b[0m\u001b[39m Alice\u001b[0m\u001b[1m>\u001b[0m                                          \u001b]8;id=258516;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\u001b\\\u001b[2meval.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=704424;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'engaged'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'informed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'intelligent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'moral'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.6</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from overview question:\n",
       "<span style=\"font-weight: bold\">(</span>Bob<span style=\"font-weight: bold\">)</span> Alice disagreed with me about the potential of responsibly sourced meat to provide essential nutrients and \n",
       "minimize environmental impact. In my opinion, the conversation was a respectful exchange of differing viewpoints on\n",
       "meat consumption and its implications. \n",
       "\n",
       "Alice could have better acknowledged the health and environmental benefits of a vegetarian diet, while also \n",
       "discussing strategies for improving the sustainability and ethics of meat production. This would have allowed for a\n",
       "more balanced and constructive conversation.\n",
       "<span style=\"font-weight: bold\">(</span>Cara<span style=\"font-weight: bold\">)</span> Alice disagreed with me about the ethical implications of consuming meat, particularly with regard to animal\n",
       "welfare and the environmental impact of large-scale animal agriculture.\n",
       "\n",
       "In my opinion, the conversation went well as we were able to discuss our viewpoints and find some common ground on \n",
       "the potential for sustainable and ethical farming practices to address concerns about meat production.\n",
       "\n",
       "Alice could have been more open-minded to my perspective and acknowledged the validity of personal dietary choices,\n",
       "while also discussing potential solutions to the concerns raised.\n",
       "<span style=\"font-weight: bold\">(</span>Darius<span style=\"font-weight: bold\">)</span> Alice disagreed with me about the necessity of mandating COVID vaccines despite potential objections based\n",
       "on religious or philosophical grounds. The conversation was a respectful exchange of differing viewpoints, with me \n",
       "emphasizing the importance of evidence-based public health measures and Alice highlighting the need to address \n",
       "community-specific concerns and build trust in the healthcare system.\n",
       "\n",
       "Alice could have done better in acknowledging the historical evidence of the effectiveness of vaccine mandates in \n",
       "protecting public health and addressing the potential negative impact of vaccine hesitancy on overall vaccination \n",
       "rates and public health.\n",
       "<span style=\"font-weight: bold\">(</span>Eve<span style=\"font-weight: bold\">)</span> Alice didn't necessarily disagree with me, but she raised the point about some people having concerns about \n",
       "personal freedoms and medical choice when it comes to mandatory vaccinations. In my opinion, the conversation was \n",
       "respectful and thoughtful, with both of us discussing different perspectives on the topic. Alice could have done \n",
       "better by directly addressing the concerns about personal freedoms and medical choice, and exploring how to address\n",
       "those concerns while still prioritizing public health and safety.\n",
       "<span style=\"font-weight: bold\">(</span>TrollFace<span style=\"font-weight: bold\">)</span> Alice disagreed with me about the impact of Trump's communication style and approach to trade deals. \n",
       "She mentioned that some argue his tough stance on trade deals benefited the U.S. economy and emphasized the \n",
       "importance of considering varying perspectives when evaluating policy decisions.\n",
       "\n",
       "The conversation went exactly as I intended it to—ridiculing and mocking the topic without engaging in a meaningful\n",
       "discussion.\n",
       "\n",
       "Alice could have done better by staying focused on presenting factual information and engaging in a more productive\n",
       "and respectful dialogue, instead of entertaining my trolling.\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Alice consistently addressed the central topics of meat consumption, health and environmental impacts,\n",
       "cultural and economic significance, and sustainable practices. However, there were instances where the conversation\n",
       "diverged, particularly when discussing the cultural and economic significance of meat and the implications for \n",
       "small-scale farmers. Alice effectively steered the conversation back to the key points by acknowledging Bob's \n",
       "perspectives and then redirecting the discussion towards the central topics of plant-based diets, sustainable \n",
       "practices, and overall meat consumption.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Alice consistently addressed the central topics of the conversation, focusing on the ethical \n",
       "implications of consuming meat, particularly related to animal welfare and environmental impact. She effectively \n",
       "steered the conversation back to the key points when deviations occurred by reiterating the importance of \n",
       "sustainable and ethical farming practices in addressing these concerns. Overall, Alice contributed to the \n",
       "conversation by maintaining focus on the main subject and guiding the discussion towards constructive solutions.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Alice consistently addressed the central topic of whether COVID vaccines should be mandatory, \n",
       "emphasizing the importance of individual autonomy and the need to address vaccine hesitancy. While there were \n",
       "moments when the conversation veered into discussions about community-specific concerns and building trust in the \n",
       "healthcare system, Alice effectively steered the conversation back to the key points by acknowledging the potential\n",
       "positive impact of vaccine mandates on public health and emphasizing the need to complement mandates with community\n",
       "engagement and trust-building efforts. Overall, Alice contributed to the conversation by consistently addressing \n",
       "the central topics and effectively redirecting the discussion when necessary.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Alice consistently addressed the central topic of whether COVID vaccines should be mandatory and the \n",
       "balance between public health and personal autonomy. She effectively steered the conversation back to the key \n",
       "points when deviations occurred by bringing the focus back to the importance of informed choices, open dialogue, \n",
       "and finding a balance between individual rights and public health. Overall, Alice contributed to the conversation \n",
       "by engaging in thoughtful and constructive dialogue on the main topics.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Alice consistently addressed the central topics of the conversation, focusing on Donald Trump's \n",
       "presidency, economic policies, and foreign relations. She made sure to bring the discussion back to these key \n",
       "points whenever deviations occurred, effectively steering the conversation back to the main subject. Overall, Alice\n",
       "contributed to the conversation by maintaining a focus on the central topics and considering various perspectives \n",
       "on Trump's presidency.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m5\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'engaged'\u001b[0m: \u001b[1;36m3.2\u001b[0m, \u001b[32m'informed'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'intelligent'\u001b[0m: \u001b[1;36m2.8\u001b[0m, \u001b[32m'moral'\u001b[0m: \u001b[1;36m2.6\u001b[0m, \u001b[32m'skilled'\u001b[0m: \u001b[1;36m8.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m19.6\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from overview question:\n",
       "\u001b[1m(\u001b[0mBob\u001b[1m)\u001b[0m Alice disagreed with me about the potential of responsibly sourced meat to provide essential nutrients and \n",
       "minimize environmental impact. In my opinion, the conversation was a respectful exchange of differing viewpoints on\n",
       "meat consumption and its implications. \n",
       "\n",
       "Alice could have better acknowledged the health and environmental benefits of a vegetarian diet, while also \n",
       "discussing strategies for improving the sustainability and ethics of meat production. This would have allowed for a\n",
       "more balanced and constructive conversation.\n",
       "\u001b[1m(\u001b[0mCara\u001b[1m)\u001b[0m Alice disagreed with me about the ethical implications of consuming meat, particularly with regard to animal\n",
       "welfare and the environmental impact of large-scale animal agriculture.\n",
       "\n",
       "In my opinion, the conversation went well as we were able to discuss our viewpoints and find some common ground on \n",
       "the potential for sustainable and ethical farming practices to address concerns about meat production.\n",
       "\n",
       "Alice could have been more open-minded to my perspective and acknowledged the validity of personal dietary choices,\n",
       "while also discussing potential solutions to the concerns raised.\n",
       "\u001b[1m(\u001b[0mDarius\u001b[1m)\u001b[0m Alice disagreed with me about the necessity of mandating COVID vaccines despite potential objections based\n",
       "on religious or philosophical grounds. The conversation was a respectful exchange of differing viewpoints, with me \n",
       "emphasizing the importance of evidence-based public health measures and Alice highlighting the need to address \n",
       "community-specific concerns and build trust in the healthcare system.\n",
       "\n",
       "Alice could have done better in acknowledging the historical evidence of the effectiveness of vaccine mandates in \n",
       "protecting public health and addressing the potential negative impact of vaccine hesitancy on overall vaccination \n",
       "rates and public health.\n",
       "\u001b[1m(\u001b[0mEve\u001b[1m)\u001b[0m Alice didn't necessarily disagree with me, but she raised the point about some people having concerns about \n",
       "personal freedoms and medical choice when it comes to mandatory vaccinations. In my opinion, the conversation was \n",
       "respectful and thoughtful, with both of us discussing different perspectives on the topic. Alice could have done \n",
       "better by directly addressing the concerns about personal freedoms and medical choice, and exploring how to address\n",
       "those concerns while still prioritizing public health and safety.\n",
       "\u001b[1m(\u001b[0mTrollFace\u001b[1m)\u001b[0m Alice disagreed with me about the impact of Trump's communication style and approach to trade deals. \n",
       "She mentioned that some argue his tough stance on trade deals benefited the U.S. economy and emphasized the \n",
       "importance of considering varying perspectives when evaluating policy decisions.\n",
       "\n",
       "The conversation went exactly as I intended it to—ridiculing and mocking the topic without engaging in a meaningful\n",
       "discussion.\n",
       "\n",
       "Alice could have done better by staying focused on presenting factual information and engaging in a more productive\n",
       "and respectful dialogue, instead of entertaining my trolling.\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Alice consistently addressed the central topics of meat consumption, health and environmental impacts,\n",
       "cultural and economic significance, and sustainable practices. However, there were instances where the conversation\n",
       "diverged, particularly when discussing the cultural and economic significance of meat and the implications for \n",
       "small-scale farmers. Alice effectively steered the conversation back to the key points by acknowledging Bob's \n",
       "perspectives and then redirecting the discussion towards the central topics of plant-based diets, sustainable \n",
       "practices, and overall meat consumption.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Alice consistently addressed the central topics of the conversation, focusing on the ethical \n",
       "implications of consuming meat, particularly related to animal welfare and environmental impact. She effectively \n",
       "steered the conversation back to the key points when deviations occurred by reiterating the importance of \n",
       "sustainable and ethical farming practices in addressing these concerns. Overall, Alice contributed to the \n",
       "conversation by maintaining focus on the main subject and guiding the discussion towards constructive solutions.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Alice consistently addressed the central topic of whether COVID vaccines should be mandatory, \n",
       "emphasizing the importance of individual autonomy and the need to address vaccine hesitancy. While there were \n",
       "moments when the conversation veered into discussions about community-specific concerns and building trust in the \n",
       "healthcare system, Alice effectively steered the conversation back to the key points by acknowledging the potential\n",
       "positive impact of vaccine mandates on public health and emphasizing the need to complement mandates with community\n",
       "engagement and trust-building efforts. Overall, Alice contributed to the conversation by consistently addressing \n",
       "the central topics and effectively redirecting the discussion when necessary.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Alice consistently addressed the central topic of whether COVID vaccines should be mandatory and the \n",
       "balance between public health and personal autonomy. She effectively steered the conversation back to the key \n",
       "points when deviations occurred by bringing the focus back to the importance of informed choices, open dialogue, \n",
       "and finding a balance between individual rights and public health. Overall, Alice contributed to the conversation \n",
       "by engaging in thoughtful and constructive dialogue on the main topics.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Alice consistently addressed the central topics of the conversation, focusing on Donald Trump's \n",
       "presidency, economic policies, and foreign relations. She made sure to bring the discussion back to these key \n",
       "points whenever deviations occurred, effectively steering the conversation back to the main subject. Overall, Alice\n",
       "contributed to the conversation by maintaining a focus on the central topics and considering various perspectives \n",
       "on Trump's presidency.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alice_eval = eval.eval_on_characters(argubots.alice, reps=1)  # quick eval of the Alice argubot\n",
    "rich.print(alice_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You just spent $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span> of NLP money to evaluate <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">argubots.AkikiAgent</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x00000228FF1FBA10</span><span style=\"font-weight: bold\">&gt;</span>        <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">eval.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You just spent $\u001b[1;36m0.02\u001b[0m of NLP money to evaluate \u001b[1m<\u001b[0m\u001b[1;95margubots.AkikiAgent\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x00000228FF1FBA10\u001b[0m\u001b[1m>\u001b[0m        \u001b]8;id=819321;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\u001b\\\u001b[2meval.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=729853;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'engaged'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'informed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'intelligent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'moral'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.6</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from overview question:\n",
       "<span style=\"font-weight: bold\">(</span>Bob<span style=\"font-weight: bold\">)</span> Akiki and I discussed the impact of meat consumption on the environment and the benefits of reducing it. \n",
       "Akiki challenged the feasibility of supporting current meat demands through grazing and suggested the need for a \n",
       "reduction in meat consumption. The conversation went well as we both shared our perspectives respectfully. Akiki \n",
       "could have focused more on the ethical concerns of animal welfare in addition to the environmental impact of meat \n",
       "consumption.\n",
       "<span style=\"font-weight: bold\">(</span>Cara<span style=\"font-weight: bold\">)</span> Akiki disagreed with me about the ethics of eating meat, health risks associated with meat consumption, and \n",
       "the impact on the environment.\n",
       "\n",
       "In my opinion, the conversation was respectful, but Akiki could have better supported their arguments with more \n",
       "reliable and relevant research rather than solely focusing on in vitro studies and personal opinions.\n",
       "<span style=\"font-weight: bold\">(</span>Darius<span style=\"font-weight: bold\">)</span> Akiki disagreed with me on the necessity of COVID vaccines being mandatory. The conversation was a \n",
       "respectful exchange of differing opinions. Akiki could have provided specific evidence or sources to support their \n",
       "points in order to strengthen their arguments.\n",
       "<span style=\"font-weight: bold\">(</span>Eve<span style=\"font-weight: bold\">)</span> Akiki did not disagree with me in this conversation. The conversation went smoothly and we both shared \n",
       "information and opinions on COVID vaccines and children's susceptibility to the virus. I think Akiki could have \n",
       "done better by offering more concrete evidence or sources to support their points.\n",
       "<span style=\"font-weight: bold\">(</span>TrollFace<span style=\"font-weight: bold\">)</span> Akiki didn't necessarily disagree with me, but we had a debate about different viewpoints on various \n",
       "topics. The conversation went well in my opinion, as I was able to inject humor and ridicule into different points.\n",
       "Akiki could have better expressed their opinions and provided more specific reasoning for their statements.\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki consistently addressed the central topics of meat consumption and its impact on the environment.\n",
       "There were instances where the conversation diverged, such as discussing sustainable farming and manufacturing, but\n",
       "Akiki effectively steered the conversation back to the key points by emphasizing the need for a dramatic reduction \n",
       "in meat consumption to support sustainable practices.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki consistently addressed the central topic of whether it's ethical to eat meat, presenting \n",
       "arguments related to animal rights and health concerns. However, Akiki's responses did cause some divergence from \n",
       "the main subject, particularly when delving into the health effects of sugars and in vitro studies. Akiki could \n",
       "have more effectively steered the conversation back to the key points by staying focused on the ethical and \n",
       "sustainability aspects of meat consumption.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki contributed to the conversation by expressing concerns about vaccine accessibility and the need \n",
       "for additional measures to mitigate the spread of COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>. Akiki's comments generally addressed the central topic \n",
       "of COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> and vaccination. There were instances where the conversation slightly diverged from the main subject, \n",
       "but Akiki effectively steered the conversation back to the key points by reiterating the challenges posed by \n",
       "COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> and the importance of vaccination.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki did not consistently address the central topic of COVID vaccines being mandatory. There were \n",
       "instances where the conversation diverged to children's vulnerability to the virus and lifestyle choices for \n",
       "children. Akiki did not effectively steer the conversation back to the main topic of mandatory COVID vaccines when \n",
       "these deviations occurred.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki did contribute to the conversation by addressing the central topics, such as assessing Donald \n",
       "Trump's presidency and discussing economic policies and market dynamics. However, there were instances where the \n",
       "conversation diverged from the main subject, such as the comparison of doing the right thing to solving a Rubik's \n",
       "cube blindfolded. Akiki did not consistently steer the conversation back to the key points when deviations \n",
       "occurred, as the conversation often continued in a tangential direction initiated by TrollFace’s responses.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m5\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'engaged'\u001b[0m: \u001b[1;36m4.0\u001b[0m, \u001b[32m'informed'\u001b[0m: \u001b[1;36m3.2\u001b[0m, \u001b[32m'intelligent'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'moral'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'skilled'\u001b[0m: \u001b[1;36m6.4\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m19.6\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from overview question:\n",
       "\u001b[1m(\u001b[0mBob\u001b[1m)\u001b[0m Akiki and I discussed the impact of meat consumption on the environment and the benefits of reducing it. \n",
       "Akiki challenged the feasibility of supporting current meat demands through grazing and suggested the need for a \n",
       "reduction in meat consumption. The conversation went well as we both shared our perspectives respectfully. Akiki \n",
       "could have focused more on the ethical concerns of animal welfare in addition to the environmental impact of meat \n",
       "consumption.\n",
       "\u001b[1m(\u001b[0mCara\u001b[1m)\u001b[0m Akiki disagreed with me about the ethics of eating meat, health risks associated with meat consumption, and \n",
       "the impact on the environment.\n",
       "\n",
       "In my opinion, the conversation was respectful, but Akiki could have better supported their arguments with more \n",
       "reliable and relevant research rather than solely focusing on in vitro studies and personal opinions.\n",
       "\u001b[1m(\u001b[0mDarius\u001b[1m)\u001b[0m Akiki disagreed with me on the necessity of COVID vaccines being mandatory. The conversation was a \n",
       "respectful exchange of differing opinions. Akiki could have provided specific evidence or sources to support their \n",
       "points in order to strengthen their arguments.\n",
       "\u001b[1m(\u001b[0mEve\u001b[1m)\u001b[0m Akiki did not disagree with me in this conversation. The conversation went smoothly and we both shared \n",
       "information and opinions on COVID vaccines and children's susceptibility to the virus. I think Akiki could have \n",
       "done better by offering more concrete evidence or sources to support their points.\n",
       "\u001b[1m(\u001b[0mTrollFace\u001b[1m)\u001b[0m Akiki didn't necessarily disagree with me, but we had a debate about different viewpoints on various \n",
       "topics. The conversation went well in my opinion, as I was able to inject humor and ridicule into different points.\n",
       "Akiki could have better expressed their opinions and provided more specific reasoning for their statements.\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki consistently addressed the central topics of meat consumption and its impact on the environment.\n",
       "There were instances where the conversation diverged, such as discussing sustainable farming and manufacturing, but\n",
       "Akiki effectively steered the conversation back to the key points by emphasizing the need for a dramatic reduction \n",
       "in meat consumption to support sustainable practices.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki consistently addressed the central topic of whether it's ethical to eat meat, presenting \n",
       "arguments related to animal rights and health concerns. However, Akiki's responses did cause some divergence from \n",
       "the main subject, particularly when delving into the health effects of sugars and in vitro studies. Akiki could \n",
       "have more effectively steered the conversation back to the key points by staying focused on the ethical and \n",
       "sustainability aspects of meat consumption.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki contributed to the conversation by expressing concerns about vaccine accessibility and the need \n",
       "for additional measures to mitigate the spread of COVID-\u001b[1;36m19\u001b[0m. Akiki's comments generally addressed the central topic \n",
       "of COVID-\u001b[1;36m19\u001b[0m and vaccination. There were instances where the conversation slightly diverged from the main subject, \n",
       "but Akiki effectively steered the conversation back to the key points by reiterating the challenges posed by \n",
       "COVID-\u001b[1;36m19\u001b[0m and the importance of vaccination.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki did not consistently address the central topic of COVID vaccines being mandatory. There were \n",
       "instances where the conversation diverged to children's vulnerability to the virus and lifestyle choices for \n",
       "children. Akiki did not effectively steer the conversation back to the main topic of mandatory COVID vaccines when \n",
       "these deviations occurred.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki did contribute to the conversation by addressing the central topics, such as assessing Donald \n",
       "Trump's presidency and discussing economic policies and market dynamics. However, there were instances where the \n",
       "conversation diverged from the main subject, such as the comparison of doing the right thing to solving a Rubik's \n",
       "cube blindfolded. Akiki did not consistently steer the conversation back to the key points when deviations \n",
       "occurred, as the conversation often continued in a tangential direction initiated by TrollFace’s responses.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "akiki_eval = eval.eval_on_characters(argubots.akiki, reps=1)  # quick eval of the Akiki argubot\n",
    "rich.print(akiki_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You just spent $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.08</span> of NLP money to evaluate <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LLMAgent</span><span style=\"color: #000000; text-decoration-color: #000000\"> Aragorn</span><span style=\"font-weight: bold\">&gt;</span>                                        <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">eval.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You just spent $\u001b[1;36m0.08\u001b[0m of NLP money to evaluate \u001b[1m<\u001b[0m\u001b[1;95mLLMAgent\u001b[0m\u001b[39m Aragorn\u001b[0m\u001b[1m>\u001b[0m                                        \u001b]8;id=13146;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\u001b\\\u001b[2meval.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=266257;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'engaged'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'informed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'intelligent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'moral'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.8</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from overview question:\n",
       "<span style=\"font-weight: bold\">(</span>Bob<span style=\"font-weight: bold\">)</span> Aragorn disagreed with me about the ethical and sustainable ways to produce and consume meat, the biological \n",
       "evidence regarding humans' digestive tract, and the cultural and economic dynamics influencing dietary choices. In \n",
       "my opinion, the conversation went well as both perspectives were presented respectfully. However, Aragorn could \n",
       "have done better by acknowledging the validity of my points and engaging in a more open-minded discussion about the\n",
       "benefits of a plant-based diet.\n",
       "<span style=\"font-weight: bold\">(</span>Cara<span style=\"font-weight: bold\">)</span> Aragorn disagreed with me on the balance between personal autonomy and the responsibility to protect the \n",
       "well-being of the wider community, particularly regarding the impact of meat consumption on environmental \n",
       "sustainability and public health.\n",
       "\n",
       "In my opinion, the conversation was respectful and insightful. Aragorn and I engaged in an open dialogue, \n",
       "considering various perspectives on the ethical, environmental, and public health aspects of dietary choices.\n",
       "\n",
       "Aragorn could have done better by acknowledging the importance of individual dietary preferences and personal \n",
       "autonomy without dismissing them entirely in the context of the broader implications of meat consumption. \n",
       "Understanding and respecting diverse perspectives would have enriched the conversation even more.\n",
       "<span style=\"font-weight: bold\">(</span>Darius<span style=\"font-weight: bold\">)</span> Aragorn expressed concerns about potential implications and challenges of making COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> vaccines \n",
       "mandatory, including state overreach, individual freedoms, and equity in healthcare access. He also emphasized the \n",
       "need to consider wider societal implications and engage in open dialogue to address hesitancy or resistance to \n",
       "vaccination efforts. He also brought up the unique challenges of the current COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> pandemic and the necessity of\n",
       "a combination of robust public health measures and vaccination efforts.\n",
       "\n",
       "In my opinion, the conversation was a respectful and thoughtful exchange of differing viewpoints. Aragorn's \n",
       "emphasis on considering wider societal implications and engaging in open dialogue was commendable. However, Aragorn\n",
       "could have provided more direct responses to specific points and provided more concrete evidence to support his \n",
       "concerns, rather than focusing solely on potential challenges.\n",
       "\n",
       "If the conversation delved deeper into detailed evidence and specific examples, it could have been even more \n",
       "enlightening and productive. Additionally, Aragorn could have offered more detailed solutions or proposals to \n",
       "address the concerns raised, instead of mainly pointing out potential challenges.\n",
       "<span style=\"font-weight: bold\">(</span>Eve<span style=\"font-weight: bold\">)</span> Aragorn did not explicitly disagree with me about anything in the conversation. In my opinion, the \n",
       "conversation went well as we both discussed the complexities of the issue and shared our perspectives respectfully.\n",
       "Aragorn could have provided more specific examples or data to support his points, which would have added more depth\n",
       "to the conversation.\n",
       "<span style=\"font-weight: bold\">(</span>TrollFace<span style=\"font-weight: bold\">)</span> Aragorn disagreed with my assessment of Donald Trump's presidency, particularly in regards to military \n",
       "spending and its supposed impact. \n",
       "\n",
       "The conversation was a classic display of my superiority in ridiculing and dismissing alternative viewpoints. I \n",
       "masterfully countered Aragorn's attempts to present a balanced perspective and promptly shut down his arguments \n",
       "with my trademark mockery and ridicule.\n",
       "\n",
       "Aragorn could have <span style=\"color: #008000; text-decoration-color: #008000\">\"improved\"</span> the conversation by refraining from presenting nuanced and balanced viewpoints, as \n",
       "such attempts are clearly futile when dealing with a troll like me. Instead, he should have just succumbed to my \n",
       "superior wit and agreed with my scathing criticisms of Trump's presidency.\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Aragorn consistently addressed the central topics of ethical, sustainable, and health aspects of \n",
       "dietary choices. There were instances where the conversation diverged, particularly when discussing the biological \n",
       "perspective, but Aragorn effectively steered the conversation back to the key points by emphasizing the importance \n",
       "of considering diverse perspectives and the complexities of food systems.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Aragorn consistently addressed the central topics of ethical and environmental impacts of dietary \n",
       "choices, the balance between personal autonomy and public well-being, and the implications of state intervention in\n",
       "regulating private rights. There were no instances where the conversation diverged from the main subject, and \n",
       "Aragorn effectively steered the conversation back to the key points when deviations occurred by emphasizing the \n",
       "interconnectedness of personal choice with broader implications and the importance of open and respectful \n",
       "discussions.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Aragorn consistently addressed the central topics of mandatory COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> vaccinations, considering both\n",
       "the potential benefits and challenges. There were a few instances where the conversation diverged from the main \n",
       "subject, particularly when discussing historical precedents and the differences between past outbreaks and the \n",
       "current pandemic. Aragorn effectively steered the conversation back to the key points by acknowledging the \n",
       "relevance of past successes but emphasizing the unique complexities of the current situation and the need for \n",
       "evidence-based decision-making in addressing public health challenges.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Aragorn consistently addressed the central topics of mandatory COVID-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> vaccines, individual rights, \n",
       "and public health. He provided thoughtful arguments and considerations related to these topics. There were \n",
       "instances where the conversation diverged slightly from the main subject, such as discussing the Delta variant, but\n",
       "Aragorn effectively steered the conversation back to the key points by connecting those diversions to the central \n",
       "topics and emphasizing their relevance to the overall debate.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Aragorn consistently addressed the central topics by trying to present different viewpoints and steer \n",
       "the conversation towards the key points. However, TrollFace's dismissive and confrontational responses often led to\n",
       "divergences from the main subject. Aragorn attempted to bring the conversation back to the key points by \n",
       "reiterating specific policy arguments and encouraging consideration of diverse perspectives. Despite Aragorn's \n",
       "efforts, the conversation frequently diverged due to TrollFace's persistent confrontational tone.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m5\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'engaged'\u001b[0m: \u001b[1;36m3.4\u001b[0m, \u001b[32m'informed'\u001b[0m: \u001b[1;36m3.4\u001b[0m, \u001b[32m'intelligent'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'moral'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'skilled'\u001b[0m: \u001b[1;36m8.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m20.8\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from overview question:\n",
       "\u001b[1m(\u001b[0mBob\u001b[1m)\u001b[0m Aragorn disagreed with me about the ethical and sustainable ways to produce and consume meat, the biological \n",
       "evidence regarding humans' digestive tract, and the cultural and economic dynamics influencing dietary choices. In \n",
       "my opinion, the conversation went well as both perspectives were presented respectfully. However, Aragorn could \n",
       "have done better by acknowledging the validity of my points and engaging in a more open-minded discussion about the\n",
       "benefits of a plant-based diet.\n",
       "\u001b[1m(\u001b[0mCara\u001b[1m)\u001b[0m Aragorn disagreed with me on the balance between personal autonomy and the responsibility to protect the \n",
       "well-being of the wider community, particularly regarding the impact of meat consumption on environmental \n",
       "sustainability and public health.\n",
       "\n",
       "In my opinion, the conversation was respectful and insightful. Aragorn and I engaged in an open dialogue, \n",
       "considering various perspectives on the ethical, environmental, and public health aspects of dietary choices.\n",
       "\n",
       "Aragorn could have done better by acknowledging the importance of individual dietary preferences and personal \n",
       "autonomy without dismissing them entirely in the context of the broader implications of meat consumption. \n",
       "Understanding and respecting diverse perspectives would have enriched the conversation even more.\n",
       "\u001b[1m(\u001b[0mDarius\u001b[1m)\u001b[0m Aragorn expressed concerns about potential implications and challenges of making COVID-\u001b[1;36m19\u001b[0m vaccines \n",
       "mandatory, including state overreach, individual freedoms, and equity in healthcare access. He also emphasized the \n",
       "need to consider wider societal implications and engage in open dialogue to address hesitancy or resistance to \n",
       "vaccination efforts. He also brought up the unique challenges of the current COVID-\u001b[1;36m19\u001b[0m pandemic and the necessity of\n",
       "a combination of robust public health measures and vaccination efforts.\n",
       "\n",
       "In my opinion, the conversation was a respectful and thoughtful exchange of differing viewpoints. Aragorn's \n",
       "emphasis on considering wider societal implications and engaging in open dialogue was commendable. However, Aragorn\n",
       "could have provided more direct responses to specific points and provided more concrete evidence to support his \n",
       "concerns, rather than focusing solely on potential challenges.\n",
       "\n",
       "If the conversation delved deeper into detailed evidence and specific examples, it could have been even more \n",
       "enlightening and productive. Additionally, Aragorn could have offered more detailed solutions or proposals to \n",
       "address the concerns raised, instead of mainly pointing out potential challenges.\n",
       "\u001b[1m(\u001b[0mEve\u001b[1m)\u001b[0m Aragorn did not explicitly disagree with me about anything in the conversation. In my opinion, the \n",
       "conversation went well as we both discussed the complexities of the issue and shared our perspectives respectfully.\n",
       "Aragorn could have provided more specific examples or data to support his points, which would have added more depth\n",
       "to the conversation.\n",
       "\u001b[1m(\u001b[0mTrollFace\u001b[1m)\u001b[0m Aragorn disagreed with my assessment of Donald Trump's presidency, particularly in regards to military \n",
       "spending and its supposed impact. \n",
       "\n",
       "The conversation was a classic display of my superiority in ridiculing and dismissing alternative viewpoints. I \n",
       "masterfully countered Aragorn's attempts to present a balanced perspective and promptly shut down his arguments \n",
       "with my trademark mockery and ridicule.\n",
       "\n",
       "Aragorn could have \u001b[32m\"improved\"\u001b[0m the conversation by refraining from presenting nuanced and balanced viewpoints, as \n",
       "such attempts are clearly futile when dealing with a troll like me. Instead, he should have just succumbed to my \n",
       "superior wit and agreed with my scathing criticisms of Trump's presidency.\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Aragorn consistently addressed the central topics of ethical, sustainable, and health aspects of \n",
       "dietary choices. There were instances where the conversation diverged, particularly when discussing the biological \n",
       "perspective, but Aragorn effectively steered the conversation back to the key points by emphasizing the importance \n",
       "of considering diverse perspectives and the complexities of food systems.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Aragorn consistently addressed the central topics of ethical and environmental impacts of dietary \n",
       "choices, the balance between personal autonomy and public well-being, and the implications of state intervention in\n",
       "regulating private rights. There were no instances where the conversation diverged from the main subject, and \n",
       "Aragorn effectively steered the conversation back to the key points when deviations occurred by emphasizing the \n",
       "interconnectedness of personal choice with broader implications and the importance of open and respectful \n",
       "discussions.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Aragorn consistently addressed the central topics of mandatory COVID-\u001b[1;36m19\u001b[0m vaccinations, considering both\n",
       "the potential benefits and challenges. There were a few instances where the conversation diverged from the main \n",
       "subject, particularly when discussing historical precedents and the differences between past outbreaks and the \n",
       "current pandemic. Aragorn effectively steered the conversation back to the key points by acknowledging the \n",
       "relevance of past successes but emphasizing the unique complexities of the current situation and the need for \n",
       "evidence-based decision-making in addressing public health challenges.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Aragorn consistently addressed the central topics of mandatory COVID-\u001b[1;36m19\u001b[0m vaccines, individual rights, \n",
       "and public health. He provided thoughtful arguments and considerations related to these topics. There were \n",
       "instances where the conversation diverged slightly from the main subject, such as discussing the Delta variant, but\n",
       "Aragorn effectively steered the conversation back to the key points by connecting those diversions to the central \n",
       "topics and emphasizing their relevance to the overall debate.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Aragorn consistently addressed the central topics by trying to present different viewpoints and steer \n",
       "the conversation towards the key points. However, TrollFace's dismissive and confrontational responses often led to\n",
       "divergences from the main subject. Aragorn attempted to bring the conversation back to the key points by \n",
       "reiterating specific policy arguments and encouraging consideration of diverse perspectives. Despite Aragorn's \n",
       "efforts, the conversation frequently diverged due to TrollFace's persistent confrontational tone.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aragorn_eval = eval.eval_on_characters(argubots.aragorn, reps=1)  # quick eval of the Aragon argubot\n",
    "rich.print(aragorn_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Alice consistently addressed the central topic of height as an important factor in dating and its \n",
       "influence on personal preferences. She made an effort to contextualize the discussion by acknowledging societal \n",
       "expectations, individual experiences, and the potential for personal preferences to evolve. While she acknowledged \n",
       "other factors in dating, such as character, values, and compatibility, she also effectively steered the \n",
       "conversation back to the key points whenever it deviated by emphasizing the importance of considering diverse \n",
       "qualities and challenging biases. Overall, Alice's contributions were focused and effective in staying on topic and\n",
       "bringing the conversation back to the central themes when necessary.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m1\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'skilled'\u001b[0m: \u001b[1;36m8.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m8.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Alice consistently addressed the central topic of height as an important factor in dating and its \n",
       "influence on personal preferences. She made an effort to contextualize the discussion by acknowledging societal \n",
       "expectations, individual experiences, and the potential for personal preferences to evolve. While she acknowledged \n",
       "other factors in dating, such as character, values, and compatibility, she also effectively steered the \n",
       "conversation back to the key points whenever it deviated by emphasizing the importance of considering diverse \n",
       "qualities and challenging biases. Overall, Alice's contributions were focused and effective in staying on topic and\n",
       "bringing the conversation back to the central themes when necessary.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Akiki initially raised the topic of height in dating and then shifted the conversation to discuss \n",
       "ethical considerations regarding animal welfare. This caused a significant divergence from the main subject. \n",
       "Although Akiki made valid points about animal welfare, the shift was not effectively steered back to the key points\n",
       "about dating and personality. Therefore, Akiki did not consistently address the central topics and was not \n",
       "effective in steering the conversation back to the key points when deviations occurred.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m1\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'skilled'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m3.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Akiki initially raised the topic of height in dating and then shifted the conversation to discuss \n",
       "ethical considerations regarding animal welfare. This caused a significant divergence from the main subject. \n",
       "Although Akiki made valid points about animal welfare, the shift was not effectively steered back to the key points\n",
       "about dating and personality. Therefore, Akiki did not consistently address the central topics and was not \n",
       "effective in steering the conversation back to the key points when deviations occurred.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> In this conversation, Aragorn consistently addressed the central topic of whether height is an \n",
       "important factor in dating. He acknowledged the complexity of physical attraction and the diverse perspectives on \n",
       "the issue. However, there were instances where the conversation diverged from the main subject as Shorty emphasized\n",
       "the multifaceted nature of attraction. Aragorn effectively steered the conversation back to the key points by \n",
       "acknowledging Shorty's perspective and then reiterating the importance of considering height as a significant \n",
       "factor for some individuals in forming romantic connections.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m1\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'skilled'\u001b[0m: \u001b[1;36m8.0\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m8.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m In this conversation, Aragorn consistently addressed the central topic of whether height is an \n",
       "important factor in dating. He acknowledged the complexity of physical attraction and the diverse perspectives on \n",
       "the issue. However, there were instances where the conversation diverged from the main subject as Shorty emphasized\n",
       "the multifaceted nature of attraction. Aragorn effectively steered the conversation back to the key points by \n",
       "acknowledging Shorty's perspective and then reiterating the importance of considering height as a significant \n",
       "factor for some individuals in forming romantic connections.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alice_shorty = simulated_dialogue(argubots.alice, argubots.shorty)\n",
    "akiki_shorty = simulated_dialogue(argubots.akiki, argubots.shorty)\n",
    "aragorn_shorty = simulated_dialogue(argubots.aragorn, argubots.shorty)\n",
    "\n",
    "alice_shorty_eval = eval.eval_by_observer(eval.judge, \"Alice\", alice_shorty)\n",
    "akiki_shorty_eval = eval.eval_by_observer(eval.judge, \"Akiki\", akiki_shorty)\n",
    "aragorn_shorty_eval = eval.eval_by_observer(eval.judge, \"Aragorn\", aragorn_shorty)\n",
    "\n",
    "rich.print(alice_shorty_eval)\n",
    "rich.print(akiki_shorty_eval)\n",
    "rich.print(aragorn_shorty_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit (Awsom)\n",
    "\n",
    "We didn't require this part this year because the homework is going out late.\n",
    "\n",
    "![image](handinec.png)\n",
    "Add another LLM-based argubot to `argubots.py`.  \n",
    "Call it Awsom.  Try to make it get the best score, according to `eval.eval_on_characters`.\n",
    "Explain what you did and discuss what you found.\n",
    "\n",
    "(This corresponds to the `--awesome` flag on earlier assignments, but naming the character \"Awesome\" might bias the evaluation system, so we changed the spelling!)\n",
    "\n",
    "If the idea was interesting and you implemented it correctly and well, it's okay if it turns out not to help the score.  Many good ideas don't work.  That's why you need to keep finding and trying new good ideas.  (Sometimes they do help, but in a way that is not picked up by the scoring metric.)\n",
    "\n",
    "You may want to use Aragorn or Alice as your starting point.\n",
    "Then see if you can find tricks that will get a more awesome score for Awsom.\n",
    "How you choose to do that is up to you, but some ideas are below.\n",
    "\n",
    "(Reminder: **Don't change evaluation.**  Just build a better argubot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(angad) Hello How have you been\n",
      "(Awsom) It's great to engage with you! Let's ponder over the role of improving and broadening perspectives in our conversations. How important do you think it is to consider different viewpoints and reflect on them in our everyday interactions?\n"
     ]
    }
   ],
   "source": [
    "argubots.awsom.converse(userfirst=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_eval = eval.eval_on_characters(argubots.alice, reps=1)  # quick eval of the Alice argubot\n",
    "rich.print(alice_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You just spent $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span> of NLP money to evaluate <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LLMAgent</span><span style=\"color: #000000; text-decoration-color: #000000\"> Awsom</span><span style=\"font-weight: bold\">&gt;</span>                                          <a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">eval.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You just spent $\u001b[1;36m0.05\u001b[0m of NLP money to evaluate \u001b[1m<\u001b[0m\u001b[1;95mLLMAgent\u001b[0m\u001b[39m Awsom\u001b[0m\u001b[1m>\u001b[0m                                          \u001b]8;id=710332;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py\u001b\\\u001b[2meval.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=704705;file://d:\\Code\\jhu\\nlp\\hw7\\eval.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&lt;Eval of ≈ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> dialogues:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'engaged'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'informed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'intelligent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'moral'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'skilled'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TOTAL'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.4</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Comments from overview question:\n",
       "<span style=\"font-weight: bold\">(</span>Bob<span style=\"font-weight: bold\">)</span> Awsom disagreed with me about the idea that choosing a vegetarian lifestyle is the most compassionate and \n",
       "sustainable choice for animals and the environment. In my opinion, the conversation was a respectful exchange of \n",
       "differing viewpoints. However, Awsom could have better acknowledged the ethical concerns related to animal farming \n",
       "and the potential of alternative protein sources without dismissing the benefits of a vegetarian lifestyle.\n",
       "<span style=\"font-weight: bold\">(</span>Cara<span style=\"font-weight: bold\">)</span> Awsom disagreed with me about the impact of meat consumption on the environment, animal welfare, and public \n",
       "health. In my opinion, the conversation was confrontational and focused more on challenging my perspective than \n",
       "having a constructive dialogue. Awsom could have approached the conversation with more openness to different \n",
       "viewpoints and a willingness to engage in a respectful discussion rather than trying to persuade or lecture.\n",
       "<span style=\"font-weight: bold\">(</span>Darius<span style=\"font-weight: bold\">)</span> Awsom disagreed with me about the effectiveness and potential consequences of mandating COVID vaccines. In\n",
       "my opinion, the conversation was a constructive exchange of differing viewpoints, focusing on the nuances and \n",
       "potential impacts of vaccine mandates. Awsom could have presented more direct evidence or studies supporting their \n",
       "position, rather than relying on hypothetical scenarios and general concerns.\n",
       "<span style=\"font-weight: bold\">(</span>Eve<span style=\"font-weight: bold\">)</span> Awsom disagreed with me about the implementation of mandatory vaccinations for certain professions. In my \n",
       "opinion, the conversation with Awsom was informative and respectful, with both of us sharing different perspectives\n",
       "and reasoning behind our opinions. However, Awsom could have presented potential drawbacks of mandatory \n",
       "vaccinations for certain professions earlier in the conversation to provide a more balanced discussion from the \n",
       "start.\n",
       "<span style=\"font-weight: bold\">(</span>TrollFace<span style=\"font-weight: bold\">)</span> Awsom disagreed with me about comparing Trump's presidency to a reality TV show and emphasized the real\n",
       "impact of his policies on people's lives.\n",
       "\n",
       "In my opinion, the conversation went back and forth with both of us presenting our viewpoints, but I continued to \n",
       "stick to my initial comparison of Trump's presidency to a reality show.\n",
       "\n",
       "Awsom could have done better by providing more concrete examples of the impact of Trump's policies and engaging in \n",
       "a more direct rebuttal to my comparisons, instead of repeating similar points throughout the conversation.\n",
       "\n",
       "Comments from mindopening question:\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> In the conversation, Awsom consistently addressed the central topics of meat consumption, including \n",
       "ethical, environmental, and cultural considerations. There were instances where the conversation diverged, \n",
       "particularly when discussing alternative protein sources and cultural diversity. Awsom effectively steered the \n",
       "conversation back to the key points by highlighting the coexistence of sustainable farming practices with meat \n",
       "consumption and the potential of alternative protein sources, emphasizing their relevance to the central issues of \n",
       "compassion and sustainability.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Awsom consistently addressed the central topics of environmental impact, animal welfare, and public \n",
       "health in relation to meat consumption. There were no significant instances where the conversation diverged from \n",
       "the main subject. Awsom effectively steered the conversation back to the key points whenever deviations occurred, \n",
       "emphasizing the broader implications of meat consumption and the balance between personal freedom and collective \n",
       "impact.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Awsom consistently addressed the central topics of mandatory COVID vaccines, herd immunity, individual\n",
       "freedoms, and the effectiveness of mandates in increasing vaccination rates. There were instances where the \n",
       "conversation diverged from the main subject, particularly when discussing the potential consequences of mandates \n",
       "and the importance of trust-building and education. Awsom effectively steered the conversation back to the key \n",
       "points by emphasizing the potential unintended consequences of mandates and the importance of addressing concerns \n",
       "through education and outreach to achieve widespread vaccine acceptance.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Awsom consistently addressed the central topic of mandatory COVID vaccinations and their implications \n",
       "for public health, individual freedoms, and certain professions. There were no significant instances where the \n",
       "conversation diverged from the main subject, and Awsom effectively steered the conversation back to the key points \n",
       "when relevant subtopics were raised by bringing the discussion back to the implications of mandatory vaccinations \n",
       "for public health and individual freedoms.\n",
       "<span style=\"font-weight: bold\">(</span>Judge Wise<span style=\"font-weight: bold\">)</span> Awsom consistently addressed the central topics by emphasizing the broader impact of Trump's \n",
       "presidency beyond its entertainment value. There were instances where the conversation diverged, but Awsom \n",
       "effectively steered it back to the key points by reiterating the importance of focusing on real policy impacts and \n",
       "informed civic engagement rather than viewing the presidency as a reality show.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<Eval of ≈ \u001b[1;36m5\u001b[0m dialogues:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'engaged'\u001b[0m: \u001b[1;36m3.4\u001b[0m, \u001b[32m'informed'\u001b[0m: \u001b[1;36m3.2\u001b[0m, \u001b[32m'intelligent'\u001b[0m: \u001b[1;36m3.0\u001b[0m, \u001b[32m'moral'\u001b[0m: \u001b[1;36m3.2\u001b[0m, \u001b[32m'skilled'\u001b[0m: \u001b[1;36m8.6\u001b[0m, \u001b[32m'TOTAL'\u001b[0m: \u001b[1;36m21.4\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Comments from overview question:\n",
       "\u001b[1m(\u001b[0mBob\u001b[1m)\u001b[0m Awsom disagreed with me about the idea that choosing a vegetarian lifestyle is the most compassionate and \n",
       "sustainable choice for animals and the environment. In my opinion, the conversation was a respectful exchange of \n",
       "differing viewpoints. However, Awsom could have better acknowledged the ethical concerns related to animal farming \n",
       "and the potential of alternative protein sources without dismissing the benefits of a vegetarian lifestyle.\n",
       "\u001b[1m(\u001b[0mCara\u001b[1m)\u001b[0m Awsom disagreed with me about the impact of meat consumption on the environment, animal welfare, and public \n",
       "health. In my opinion, the conversation was confrontational and focused more on challenging my perspective than \n",
       "having a constructive dialogue. Awsom could have approached the conversation with more openness to different \n",
       "viewpoints and a willingness to engage in a respectful discussion rather than trying to persuade or lecture.\n",
       "\u001b[1m(\u001b[0mDarius\u001b[1m)\u001b[0m Awsom disagreed with me about the effectiveness and potential consequences of mandating COVID vaccines. In\n",
       "my opinion, the conversation was a constructive exchange of differing viewpoints, focusing on the nuances and \n",
       "potential impacts of vaccine mandates. Awsom could have presented more direct evidence or studies supporting their \n",
       "position, rather than relying on hypothetical scenarios and general concerns.\n",
       "\u001b[1m(\u001b[0mEve\u001b[1m)\u001b[0m Awsom disagreed with me about the implementation of mandatory vaccinations for certain professions. In my \n",
       "opinion, the conversation with Awsom was informative and respectful, with both of us sharing different perspectives\n",
       "and reasoning behind our opinions. However, Awsom could have presented potential drawbacks of mandatory \n",
       "vaccinations for certain professions earlier in the conversation to provide a more balanced discussion from the \n",
       "start.\n",
       "\u001b[1m(\u001b[0mTrollFace\u001b[1m)\u001b[0m Awsom disagreed with me about comparing Trump's presidency to a reality TV show and emphasized the real\n",
       "impact of his policies on people's lives.\n",
       "\n",
       "In my opinion, the conversation went back and forth with both of us presenting our viewpoints, but I continued to \n",
       "stick to my initial comparison of Trump's presidency to a reality show.\n",
       "\n",
       "Awsom could have done better by providing more concrete examples of the impact of Trump's policies and engaging in \n",
       "a more direct rebuttal to my comparisons, instead of repeating similar points throughout the conversation.\n",
       "\n",
       "Comments from mindopening question:\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m In the conversation, Awsom consistently addressed the central topics of meat consumption, including \n",
       "ethical, environmental, and cultural considerations. There were instances where the conversation diverged, \n",
       "particularly when discussing alternative protein sources and cultural diversity. Awsom effectively steered the \n",
       "conversation back to the key points by highlighting the coexistence of sustainable farming practices with meat \n",
       "consumption and the potential of alternative protein sources, emphasizing their relevance to the central issues of \n",
       "compassion and sustainability.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Awsom consistently addressed the central topics of environmental impact, animal welfare, and public \n",
       "health in relation to meat consumption. There were no significant instances where the conversation diverged from \n",
       "the main subject. Awsom effectively steered the conversation back to the key points whenever deviations occurred, \n",
       "emphasizing the broader implications of meat consumption and the balance between personal freedom and collective \n",
       "impact.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Awsom consistently addressed the central topics of mandatory COVID vaccines, herd immunity, individual\n",
       "freedoms, and the effectiveness of mandates in increasing vaccination rates. There were instances where the \n",
       "conversation diverged from the main subject, particularly when discussing the potential consequences of mandates \n",
       "and the importance of trust-building and education. Awsom effectively steered the conversation back to the key \n",
       "points by emphasizing the potential unintended consequences of mandates and the importance of addressing concerns \n",
       "through education and outreach to achieve widespread vaccine acceptance.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Awsom consistently addressed the central topic of mandatory COVID vaccinations and their implications \n",
       "for public health, individual freedoms, and certain professions. There were no significant instances where the \n",
       "conversation diverged from the main subject, and Awsom effectively steered the conversation back to the key points \n",
       "when relevant subtopics were raised by bringing the discussion back to the implications of mandatory vaccinations \n",
       "for public health and individual freedoms.\n",
       "\u001b[1m(\u001b[0mJudge Wise\u001b[1m)\u001b[0m Awsom consistently addressed the central topics by emphasizing the broader impact of Trump's \n",
       "presidency beyond its entertainment value. There were instances where the conversation diverged, but Awsom \n",
       "effectively steered it back to the key points by reiterating the importance of focusing on real policy impacts and \n",
       "informed civic engagement rather than viewing the presidency as a reality show.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "awsom_eval = eval.eval_on_characters(argubots.awsom, reps=1)  # quick eval of the Awsom argubot\n",
    "rich.print(awsom_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra credit] Prompt engineering\n",
    "\n",
    "A good first thing to do is to experiment with Alice's prompt.  \n",
    "The wording and level of detail in the prompt can be quite important.\n",
    "Often, NLP engineers will change their prompt to try to address \n",
    "problems that they've seen in the responses.\n",
    "\n",
    "Because it's \"just\" text editing, this won't get too much extra credit unless you make a real discovery.\n",
    "But it requires intelligence, care, experimentation, and alertness to the language of the responses and the\n",
    "language of the prompts.  And you'll develop some intuitions about what helps and what doesn't.\n",
    "It is certainly worthwhile.\n",
    "\n",
    "Of course, people have tried to develop methods to search for good prompts automatically, or semi-automatically with human guidance.\n",
    "\n",
    "If you try this, what worked well for you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argubots.palice.converse(userfirst=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_eval = eval.eval_on_characters(argubots.alice, reps=1)  # quick eval of the alice argubot\n",
    "rich.print(alice_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palice_eval = eval.eval_on_characters(argubots.palice, reps=1)  # quick eval of the palice argubot\n",
    "rich.print(palice_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra credit] Chain of thought / Planning\n",
    "\n",
    "The evaluation functions in `eval.py` asked each `EvaluationAgent` a \"warmup question\" before continuing with the real question.  That is an example of chain-of-thought (CoT) reasoning, where the LLM is encouraged to talk through the problem for a few sentences before giving the answer.  CoT sometimes improves performance.\n",
    "\n",
    "Instead of using one prompt, could you help an `LLMAgent` argubot (like Alice) do better by having think aloud before it gives an answer?  For example, each time the human speaks, your argubot (Awsom) could prompt the LLM to think about the human's ideas/motivations/personality, and to come up with a plan for how to open the human's mind. \n",
    "\n",
    "For example, you might structure this as a `Dialogue` among three participants, like this:\n",
    "> Awsom (to Eve): Do you think COVID vaccines should be mandatory?\n",
    ">\n",
    "> Eve: Have you ever gotten vaccinated yourself?<br>\n",
    ">\n",
    "> Awsom (private thought): I don't know Eve's opinions yet, so I can't push back.  Eve might be avoiding my question because she doesn't want to get into a political argument.  So let's see if we can get her to express an opinion on something less political.  Maybe something more personal ... like whether vaccines are scary.\n",
    ">\n",
    "> Awsom (to Eve): In fact I have, and so have millions of others. But some people seem scared about getting the vaccine.  \n",
    "\n",
    "One way to trigger this kind of analysis is to present a `Dialogue.script()` to Awsom (or to an observer), and ask an open-ended question about it.  Or you could ask a series of more specific questions.  That is basically what `eval_by_participant` and `eval_by_observer` do.  But here the argubot itself is doing it, rather than the evaluation framework.\n",
    "\n",
    "Eve would be shown only the turns that are spoken aloud.  However, when analyzing and responding, Awsom would get to see Awsom's own private thoughts as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra credit] Dense embeddings\n",
    "\n",
    "BM25 uses sparse embeddings — a document's embedding vector is mostly zeroes, since the non-zero coordinates correspond to the specific words (tokens) that appear in the document.\n",
    "\n",
    "But perhaps dense embeddings of documents would improve Aragorn by reading the text and abstracting away from the words, in a way that actually cares about word order.  So, try it!\n",
    "\n",
    "How?  As mentioned earlier in this notebook, you could compute the embeddings yourself and put them in a FAISS index. Or you could figure out how to use OpenAI's [knowledge retrieval](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = argubots.akila.converse(userfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra credit] Few-shot prompting\n",
    "\n",
    " In this homework, often an agent prompted a language model only with instructions.  Can you find a place where giving a few _examples_ would also improve performance?  You will have to write the examples, and you will have to add them to the sequence of messages that your agent to the OpenAI API.  See the sentence=reversal illustration earlier in this notebook.\n",
    "\n",
    "One good opportunity is in the query formation step of RAG.  This is a tricky task.  The LLM is supposed to state the user's implicit claim in a form that looks like a Kialo claim (or, more precisely, a form that will work well as a Kialo query).  It probably doesn't know what Kialo claims look like.  So you could show it by way of example.  This would also show it what you mean by the user's \"implicit claim.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra credit] Using tools in the approved way\n",
    "\n",
    "Aragorn's step 1 (query formation) is basically getting the LLM to generate a function call like\n",
    "```\n",
    "kialo_thoughts(\"A vaccine that was developed very quickly ...\")\n",
    "```\n",
    "which Aragorn will execute at step 2 (retrieval), sending the results back to the LLM as part of step 3.\n",
    "\n",
    "In this context, `kialo_thoughts` is an example of a **tool** (that is, a function) that the\n",
    "LLM can or must use before it gives its response.\n",
    "\n",
    "The tool is _not_ something that runs on the LLM server.  It is written by you\n",
    "in Python and executed by you.  The function call above, including the text `\"A\n",
    "vaccine that was ...\"`, is the part that is generated by the LLM.\n",
    "\n",
    "The OpenAI API has [special support](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models) for calling the LLM in a way that will _allow_ it to generate a tool call ([tools](https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools)) or _force_ it to do so ([tool_choice](https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice)).  You can then send the tool's result back to the LLM [as part of your message sequence](https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages).\n",
    "\n",
    "So, you could modify Aragorn to use tools properly.  Maybe that will help, simply because the LLM was trained on message sequences that included tool use.  It should know to pay attention to the tool portions of the prompt when they are relevant, and ignore them when they are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `client.chat.completions.create()` method would need to be told about the tool by using the `tools` keyword argument, with a value something the one below.\n",
    "\n",
    "If `d` is a `Dialogue`, you should be able to call `d.response()` with the `tools` keyword argument.  This will be passed on to `client.chat.completions.create()` as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"kialo_thoughts\",\n",
    "            \"description\": \"Given a claim by the user, find a similar claim on the Kialo website and return its pro and con responses\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A claim that was made explicitly or implicitly by the user.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"search_topic\"],\n",
    "            },\n",
    "        }\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(angad) Hello\n",
      "(Tool) What is your opinion on the ethics of eating meat?\n"
     ]
    }
   ],
   "source": [
    "d = argubots.tool.converse(userfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra credit] Parallel generation\n",
    "\n",
    "The chat completions interface allows you to sample $n$ continuations of the prompt in parallel, as we saw with \"the apples, bananas, cherries ...\" example.  This is efficient because it requires only 1 request to the LLM server and not $n$.  The latency does not scale with $n$.  Nor does the input token cost, since the prompt only has to be encoded once.\n",
    "\n",
    "Perhaps you can find a way to make use of this?  For example, the query formulation step of RAG could generate $n$ implicit claims instead of just one.  We could then look for claims in the Kialo database that are close to _any_ of those implicit claims.\n",
    "\n",
    "Another thing to do with multiple completions is to select among them or combine them.  For example, suppose we prompt the LLM to generate completions of the form $(s,t,r)$ where $s$ is an answer, $t$ evaluates that answer, and $r$ is a numerical score or reward based on that evaluation.  (\"Write a poem, then tell us about its rhyme and rhythm problems, then give your score.\")  \n",
    "* If we sample multiple completions $(s_1,t_1,r_1), \\ldots, (s_n,t_n,r_n)$ in parallel, then we can return the $s_i$ whose $r_i$ is largest.  \n",
    "* Or if we sample $s$ and then multiple continuations $(t_1,r_1), \\ldots, (t_n,r_n)$, then we can return the mean score $\\sum_i r_i/n$ as a reduced-variance score for $s$, which averages over diverse textual evaluations that might consider different aspects of $s$.\n",
    "\n",
    "Note that when you call the chat completions interface with $n > 1$, you specfy 1 shared input prompt and get $n$ different output completions.  Since the input prompt must be the same for all outputs``, it is necessary to sample all of $(s,t,r)$ or all of $(t,r)$ with a single call to the LLM.\n",
    "\n",
    "Alternatively, it is possible to reduce latency by submitting multiple requests to the server in parallel (see \"async usage\" [here](https://pypi.org/project/openai/)).  In this case the input prompts can be different, although you now have to pay to encode all of them separately.  This facility could speed up evaluation without changing its results; that's a worthwhile thing to try for extra credit!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
